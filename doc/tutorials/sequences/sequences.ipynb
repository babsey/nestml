{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NESTML active dendrite third-factor STDP synapse\n",
    "==========================================\n",
    "\n",
    "In this tutorial, a neuron and synapse model are defined in NESTML that are subsequently used in a network to perform learning, prediction and replay of sequences of items, such as letters, images or sounds [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "\n",
    "Introduction\n",
    "------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charl/.local/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: 3.6.0-post0.dev0\n",
      " Built: Mar 26 2024 08:52:51\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['axes.formatter.useoffset'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['grid.color'] = 'k'\n",
    "mpl.rcParams['grid.linestyle'] = ':'\n",
    "mpl.rcParams['grid.linewidth'] = 0.5\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "mpl.rcParams['figure.figsize'] = [8., 3.]\n",
    "# plt.rcParams['font.size'] = 8\n",
    "# plt.rcParams['legend.fontsize']= 6\n",
    "# plt.rcParams['figure.figsize'] = fig_size\n",
    "# plt.rcParams['savefig.dpi'] = 300\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "# plt.rcParams['lines.linewidth'] = 1\n",
    "# plt.rcParams['text.usetex'] = False\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nest\n",
    "import nest.raster_plot\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import parameters as para\n",
    "\n",
    "import shtm\n",
    "#import shtm.model\n",
    "import shtm.helper\n",
    "from shtm import helper  # XXX\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import random\n",
    "import os\n",
    "import nest\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from pynestml.codegeneration.nest_code_generator_utils import NESTCodeGeneratorUtils\n",
    "from pynestml.codegeneration.nest_tools import NESTTools\n",
    "\n",
    "n_threads = 1   # number of threads to use for simulations. This depends on your computer hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"Instantiation of the Spiking-TemporalMemory model and its PyNEST implementation.\n",
    "\n",
    "    the model provides the following member functions: \n",
    "\n",
    "    __init__(parameters)\n",
    "    create()\n",
    "    connect()\n",
    "    simulate(t_sim)\n",
    "\n",
    "    In addition, each model may implement other model-specific member functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, sequences, vocabulary):\n",
    "        \"\"\"Initialize model and simulation instance, including\n",
    "\n",
    "        1) parameter setting,\n",
    "        2) generate sequence data,\n",
    "        3) configuration of the NEST kernel,\n",
    "        4) setting random-number generator seed, and\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params:    dict\n",
    "                   Parameter dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\nInitialising model and simulation...')\n",
    "\n",
    "        # set parameters derived from base parameters\n",
    "        self.params = helper.derived_parameters(params)\n",
    "        print(\"Model parameters: \" + str(self.params))\n",
    "\n",
    "        # data directory\n",
    "        self.data_path = self.params['label']\n",
    "\n",
    "        try:\n",
    "            os.mkdir(self.data_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(\"Data will be written to: {}\\n\".format(self.data_path))\n",
    "\n",
    "        # set network size\n",
    "        self.num_subpopulations = params['M']\n",
    "        self.num_exc_neurons = params['n_E'] * self.num_subpopulations\n",
    "\n",
    "        # initialize RNG        \n",
    "        np.random.seed(self.params['seed'])\n",
    "        random.seed(self.params['seed'])\n",
    "\n",
    "        # input stream: sequence data\n",
    "        self.sequences = sequences\n",
    "        self.vocabulary = vocabulary\n",
    "        self.length_sequence = len(self.sequences[0])\n",
    "        self.num_sequences = len(self.sequences)\n",
    "\n",
    "        # initialize the NEST kernel\n",
    "        self.__setup_nest()\n",
    "\n",
    "        # get time constant for dendriticAP rate\n",
    "        self.params['soma_params']['tau_h'] = self.__get_time_constant_dendritic_rate(\n",
    "            calibration=self.params['calibration'])\n",
    "\n",
    "    def __setup_nest(self):\n",
    "        \"\"\"Initializes the NEST kernel.\n",
    "        \"\"\"\n",
    "\n",
    "        nest.ResetKernel()\n",
    "        nest.Install(module_name)\n",
    "        nest.SetKernelStatus({\n",
    "            'resolution': self.params['dt'],\n",
    "            'print_time': self.params['print_simulation_progress'],\n",
    "            'local_num_threads': n_threads,\n",
    "            'rng_seed': self.params['seed'],\n",
    "            'dict_miss_is_error': True,\n",
    "            'overwrite_files': self.params['overwrite_files'],\n",
    "            'data_path': str(self.data_path),\n",
    "            'data_prefix': ''\n",
    "        })\n",
    "\n",
    "    def create(self):\n",
    "        \"\"\"Create and configure all network nodes (neurons + recording and stimulus devices)\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\nCreating and configuring nodes...')\n",
    "\n",
    "        # create excitatory population\n",
    "        self.__create_neuronal_populations()\n",
    "\n",
    "        # compute timing of the external inputs and recording devices\n",
    "        # TODO: this function should probably not be part of the model\n",
    "        excitation_times, excitation_times_neuron, idend_recording_times = self.__compute_timing_external_inputs(\n",
    "                self.params['DeltaT'], self.params['DeltaT_seq'], self.params['DeltaT_cue'], \n",
    "                self.params['excitation_start'], self.params['time_dend_to_somatic'])\n",
    "\n",
    "        # create spike generators\n",
    "        self.__create_spike_generators(excitation_times_neuron)\n",
    "\n",
    "        # create recording devices\n",
    "        self.__create_recording_devices(excitation_times, idend_recording_times)\n",
    "\n",
    "        # create weight recorder\n",
    "        if self.params['active_weight_recorder']:\n",
    "            self.__create_weight_recorder()\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Connects network and devices\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\nConnecting network and devices...')\n",
    "        # TODO: take into account L (number of subpopulations per character) when connecting the network\n",
    "\n",
    "        # connect excitatory population (EE)\n",
    "        if self.params['load_connections']:\n",
    "            self.__load_connections(label='ee_connections')\n",
    "        else:\n",
    "            self.__connect_excitatory_neurons()\n",
    "\n",
    "            # connect inhibitory population (II, EI, IE)\n",
    "        self.__connect_inhibitory_neurons()\n",
    "\n",
    "        # connect external input\n",
    "        self.__connect_external_inputs_to_subpopulations()\n",
    "\n",
    "        # connect neurons to the spike recorder\n",
    "        nest.Connect(self.exc_neurons, self.spike_recorder_soma)\n",
    "        nest.Connect(self.exc_neurons, self.spike_recorder_soma_)\n",
    "        nest.Connect(self.inh_neurons, self.spike_recorder_inh)\n",
    "        nest.Connect(self.inh_neurons, self.spike_recorder_inh_)\n",
    "\n",
    "        # connect multimeter for recording dendritic current\n",
    "        if self.params['evaluate_performance']:\n",
    "            nest.Connect(self.multimeter_idend_eval, self.exc_neurons)\n",
    "            nest.Connect(self.multimeter_idend_eval_, self.exc_neurons)\n",
    "            nest.Connect(self.multimeter_vm_eval_, self.exc_neurons)\n",
    "\n",
    "        # connect multimeter for recording dendritic current from all subpopulations of the last trial\n",
    "        if self.params['record_idend_last_episode']:\n",
    "            nest.Connect(self.multimeter_idend_last_episode, self.exc_neurons)\n",
    "\n",
    "        # set min synaptic strength\n",
    "        self.__set_min_synaptic_strength()\n",
    "\n",
    "    def simulate(self):\n",
    "        \"\"\"Run simulation.\n",
    "        \"\"\"\n",
    "\n",
    "        # the simulation time is set during the creation of the network  \n",
    "        if nest.Rank() == 0:\n",
    "            print('\\nSimulating {} ms.'.format(self.sim_time))\n",
    "\n",
    "        nest.Simulate(self.sim_time)\n",
    "\n",
    "    def __create_neuronal_populations(self):\n",
    "        \"\"\"'Create neuronal populations\n",
    "        \"\"\"\n",
    "\n",
    "        # create excitatory population\n",
    "        self.exc_neurons = nest.Create(self.params['soma_model'],\n",
    "                                       self.num_exc_neurons,\n",
    "                                       params=self.params['soma_params'])\n",
    "\n",
    "        # create inhibitory population\n",
    "        self.inh_neurons = nest.Create(self.params['inhibit_model'],\n",
    "                                       self.params['n_I'] * self.num_subpopulations,\n",
    "                                       params=self.params['inhibit_params'])\n",
    "\n",
    "    def __create_spike_generators(self, excitation_times_neuron):\n",
    "        \"\"\"Create spike generators\n",
    "        \"\"\"\n",
    "\n",
    "        excitation_times_soma, excitation_times_dend = excitation_times_neuron \n",
    "\n",
    "        self.input_excitation_soma = {}\n",
    "        self.input_excitation_dend = {}\n",
    "        for char in self.vocabulary:\n",
    "            self.input_excitation_soma[char] = nest.Create('spike_generator')\n",
    "            self.input_excitation_dend[char] = nest.Create('spike_generator')\n",
    "\n",
    "        # set spike generator status with the above computed excitation times\n",
    "        for char in self.vocabulary:\n",
    "            nest.SetStatus(self.input_excitation_soma[char], {'spike_times': excitation_times_soma[char]})\n",
    "\n",
    "        # this makes the first population in the sequence sparse\n",
    "        if self.params['sparse_first_char']:\n",
    "            first_chars = [char for seq in self.sequences for char in [seq[0]]]\n",
    "            for char in first_chars:\n",
    "                nest.SetStatus(self.input_excitation_dend[char], {'spike_times': excitation_times_dend[char]})\n",
    "\n",
    "    def __create_recording_devices(self, excitation_times, idend_recording_times):\n",
    "        \"\"\"Create recording devices\n",
    "        \"\"\"\n",
    "    \n",
    "        # create a spike recorder for exc neurons\n",
    "        self.spike_recorder_soma = nest.Create('spike_recorder', params={'record_to': 'ascii','label': 'somatic_spikes'})\n",
    "        self.spike_recorder_soma_ = nest.Create('spike_recorder', params={'label': 'somatic_spikes'})\n",
    "\n",
    "        # create a spike recorder for inh neurons\n",
    "        self.spike_recorder_inh = nest.Create('spike_recorder', params={'record_to': 'ascii','label': 'inh_spikes'})\n",
    "        self.spike_recorder_inh_ = nest.Create('spike_recorder', params={'label': 'inh_spikes'})\n",
    "\n",
    "        # create multimeter to record dendritic currents of exc_neurons at the time of the last element in the sequence\n",
    "        if self.params['evaluate_performance']:\n",
    "            self.multimeter_idend_eval = nest.Create('multimeter', self.num_sequences,\n",
    "                                                     params={'record_from': ['I_dend'],\n",
    "                                                             'record_to': 'ascii',\n",
    "                                                             'label': 'idend_eval'})\n",
    "            \n",
    "            self.multimeter_idend_eval_ = nest.Create('multimeter',\n",
    "                                                     params={'record_from': ['I_dend'],\n",
    "                                                             'label': 'idend_eval'})\n",
    "            self.multimeter_vm_eval_ = nest.Create('multimeter',\n",
    "                                                     params={'record_from': ['V_m'],\n",
    "                                                             'label': 'vm_eval'})\n",
    "\n",
    "\n",
    "            for i in range(self.num_sequences):\n",
    "                idend_eval_spec_dict = {'offset': idend_recording_times[i][0] + self.params['idend_record_time'],\n",
    "                                        'interval': idend_recording_times[i][1] - idend_recording_times[i][0]}\n",
    "                nest.SetStatus(self.multimeter_idend_eval[i], idend_eval_spec_dict)\n",
    "\n",
    "            #nest.SetStatus(self.multimeter_idend_eval_, {\"interval\": nest.GetKernelStatus()[\"resolution\"]})\n",
    "            #nest.SetStatus(self.multimeter_vm_eval_, {\"interval\": nest.GetKernelStatus()[\"resolution\"]})\n",
    "\n",
    "        # create multimeter for recording dendritic current from all subpopulations of the last episode\n",
    "        if self.params['record_idend_last_episode']:\n",
    "            self.multimeter_idend_last_episode = nest.Create('multimeter', params={'record_from': ['I_dend'],\n",
    "                                                                                   'record_to': 'ascii',\n",
    "                                                                                   'label': 'idend_last_episode'})\n",
    "\n",
    "            if self.params['evaluate_replay']:\n",
    "                idend_dict = {'interval': self.params['idend_recording_interval'],\n",
    "                              'start': self.params['excitation_start'],\n",
    "                              'stop': self.params['excitation_start'] \\\n",
    "                                      + len(self.sequences) * self.params['DeltaT_cue']}\n",
    "\n",
    "                nest.SetStatus(self.multimeter_idend_last_episode, idend_dict)\n",
    "            else:\n",
    "                number_elements_per_batch = sum([len(seq) for seq in self.sequences])\n",
    "                idend_dict = {'interval': self.params['idend_recording_interval'],\n",
    "                              'start': excitation_times[-number_elements_per_batch],\n",
    "                              'stop': excitation_times[-1] + self.params['pad_time']}\n",
    "\n",
    "                nest.SetStatus(self.multimeter_idend_last_episode, idend_dict)\n",
    "\n",
    "    def __create_weight_recorder(self):\n",
    "        \"\"\"Create weight recorder\n",
    "        \"\"\"\n",
    "\n",
    "        self.wr = nest.Create('weight_recorder', {'record_to': 'ascii', 'label': 'weight_recorder'})\n",
    "        #self.params['syn_dict_ee']['weight_recorder'] = self.wr\n",
    "        nest.CopyModel(params['syn_dict_ee']['synapse_model'], 'stdsp_synapse_rec', {'weight_recorder': self.wr})\n",
    "        self.params['syn_dict_ee']['synapse_model'] = 'stdsp_synapse_rec'\n",
    "\n",
    "    def __compute_timing_external_inputs(self, DeltaT, DeltaT_seq, DeltaT_cue, excitation_start, time_dend_to_somatic):\n",
    "        \"\"\"Specifies the excitation times of the external input for each sequence element,\n",
    "        subsequent sequence elements are presented  with  inter-stimulus interval DeltaT,  \n",
    "        subsequent sequences are separated in time by an inter-sequence time interval DeltaT_seq,\n",
    "        during the replay, the presented cues are seperated by an intercue time interval Delta_cue,\n",
    "        In addition this function saves the times at which a dendritic current should be recorded,\n",
    "        we don't want to record the dendritic current every time step as this consumes a lot of memory,\n",
    "        so we instead record the dendritic current every 'episodes_to_testing' episodes,\n",
    "        recording the dendritic current is essential for computing the prediction performance,\n",
    "        the dendritic current is saved only at the time of last element in the sequence,\n",
    "        this is because when assessing the prediction performance, we compute the prediction error \n",
    "        only with respect to the last element in the sequence\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        DeltaT               : float\n",
    "        DeltaT_seq           : float\n",
    "        DeltaT_cue           : float \n",
    "        excitation_start     : float\n",
    "        time_dend_to_somatic : float\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        excitation_times: list(float)\n",
    "        excitation_times_soma: dict\n",
    "        excitation_times_dend: dict\n",
    "        idend_recording_times: dict\n",
    "        \"\"\"\n",
    "\n",
    "        excitation_times_soma = defaultdict(list)\n",
    "        excitation_times_dend = defaultdict(list)\n",
    "        idend_recording_times = defaultdict(list)\n",
    "\n",
    "        excitation_times = []\n",
    "        sim_time = excitation_start\n",
    "        for le in range(self.params['learning_episodes'] + 1):\n",
    "            print(\"Learning episode: \" + str(le) + \" of \" + str(self.params['learning_episodes'] + 1))\n",
    "\n",
    "            for seq_num, sequence in enumerate(self.sequences):\n",
    "                len_seq = len(sequence)\n",
    "                for i, char in enumerate(sequence):\n",
    "\n",
    "                    if i != 0:\n",
    "                        sim_time += DeltaT\n",
    "\n",
    "                    # store time of excitation for each symbol\n",
    "                    excitation_times_soma[char] += [sim_time]\n",
    "                    if i == 0:\n",
    "                        excitation_times_dend[char] += [sim_time - time_dend_to_somatic]\n",
    "\n",
    "                    # store dendritic spike times recording\n",
    "                    if (i == len_seq - 2) and (le % self.params['episodes_to_testing'] == 0):\n",
    "                        idend_recording_times[seq_num] += [sim_time]\n",
    "\n",
    "                    excitation_times.append(sim_time)\n",
    "\n",
    "                    if self.params['evaluate_replay']:\n",
    "                        break\n",
    "\n",
    "                # set timing between sequences\n",
    "                if self.params['evaluate_replay']:\n",
    "                    sim_time += DeltaT_cue\n",
    "                else:\n",
    "                    sim_time += DeltaT_seq\n",
    "\n",
    "        # save data\n",
    "        if self.params['evaluate_performance'] or self.params['evaluate_replay']:\n",
    "            try:\n",
    "              print(\"mkdir: \" + str(self.data_path))\n",
    "              os.mkdir(self.data_path)\n",
    "            except:\n",
    "              pass\n",
    "            np.save('%s/%s' % (self.data_path, 'idend_recording_times'), idend_recording_times)\n",
    "            print(\"Saving idend_recording_times to \" + str(os.path.join(self.data_path, 'idend_recording_times')))\n",
    "            np.save('%s/%s' % (self.data_path, 'excitation_times_soma'),\n",
    "                    excitation_times_soma)\n",
    "            np.save('%s/%s' % (self.data_path, 'excitation_times'), excitation_times)\n",
    "\n",
    "        self.sim_time = sim_time\n",
    "        return excitation_times, [excitation_times_soma, excitation_times_dend], idend_recording_times\n",
    "\n",
    "    def __get_subpopulation_neurons(self, index_subpopulation):\n",
    "        \"\"\"Get neuron's indices (NEST NodeCollection) belonging to a subpopulation\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        index_subpopulation: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        NEST NodeCollection\n",
    "        \"\"\"\n",
    "\n",
    "        neurons_indices = [int(index_subpopulation) * self.params['n_E'] + i for i in\n",
    "                           range(self.params['n_E'])]\n",
    "\n",
    "        return self.exc_neurons[neurons_indices]\n",
    "\n",
    "    def __connect_excitatory_neurons(self):\n",
    "        \"\"\"Connect excitatory neurons\n",
    "        \"\"\"\n",
    "        print(\"Conn exc neurons\")\n",
    "        print(self.params['conn_dict_ee'])\n",
    "        print(self.params['syn_dict_ee'])\n",
    "        nest.Connect(self.exc_neurons, self.exc_neurons, conn_spec=self.params['conn_dict_ee'],\n",
    "                     syn_spec=self.params['syn_dict_ee'])\n",
    "#        syn = nest.GetConnections(source=self.exc_neurons, target=self.exc_neurons, synapse_model=self.params[\"syn_dict_ee\"][\"synapse_model_name\"])   # XXX\n",
    "#        assert all(np.array(syn.weight) > 0)\n",
    "#        import pdb;pdb.set_trace()\n",
    "\n",
    "    def __connect_inhibitory_neurons(self):\n",
    "        \"\"\"Connect inhibitory neurons\n",
    "        \"\"\"\n",
    "\n",
    "        for k, subpopulation_index in enumerate(range(self.num_subpopulations)):\n",
    "            # connect inhibitory population \n",
    "            subpopulation_neurons = self.__get_subpopulation_neurons(subpopulation_index)\n",
    "\n",
    "            # connect neurons within the same mini-subpopulation to the inhibitory population\n",
    "            nest.Connect(subpopulation_neurons, self.inh_neurons[k], syn_spec=self.params['syn_dict_ie'])\n",
    "\n",
    "            # connect the inhibitory neurons to the neurons within the same mini-subpopulation\n",
    "            nest.Connect(self.inh_neurons[k], subpopulation_neurons, syn_spec=self.params['syn_dict_ei'])\n",
    "\n",
    "    def __connect_external_inputs_to_subpopulations(self):\n",
    "        \"\"\"Connect external inputs to subpopulations\n",
    "        \"\"\"\n",
    "\n",
    "        # get input encoding\n",
    "        self.characters_to_subpopulations = self.__stimulus_preference(fname='characters_to_subpopulations')\n",
    "\n",
    "        # save characters_to_subpopulations for evaluation\n",
    "        if self.params['evaluate_performance'] or self.params['evaluate_replay']:\n",
    "            fname = 'characters_to_subpopulations'\n",
    "            np.save('%s/%s' % (self.data_path, fname), self.characters_to_subpopulations)\n",
    "\n",
    "        for char in self.vocabulary:\n",
    "            subpopulations_indices = self.characters_to_subpopulations[char]\n",
    "\n",
    "            # receptor type 1 correspond to the feedforward synapse of the 'iaf_psc_exp_multisynapse' model\n",
    "            for subpopulation_index in subpopulations_indices:\n",
    "                subpopulation_neurons = self.__get_subpopulation_neurons(subpopulation_index)\n",
    "                nest.Connect(self.input_excitation_soma[char], subpopulation_neurons,\n",
    "                             self.params['conn_dict_ex'], syn_spec=self.params['syn_dict_ex'])\n",
    "                nest.Connect(self.input_excitation_dend[char], subpopulation_neurons,\n",
    "                             self.params['conn_dict_edx'], syn_spec=self.params['syn_dict_edx'])\n",
    "\n",
    "    def __stimulus_preference(self, fname='characters_to_subpopulations'):\n",
    "        \"\"\"Assign a subset of subpopulations to a each element in the vocabulary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fname : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        characters_to_subpopulations: dict\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.vocabulary) * self.params['L'] > self.num_subpopulations:\n",
    "            raise ValueError(\n",
    "                \"num_subpopulations needs to be large than length_user_characters*num_subpopulations_per_character\")\n",
    "\n",
    "        characters_to_subpopulations = defaultdict(list)  # a dictionary that assigns mini-subpopulation to characters\n",
    "\n",
    "        subpopulation_indices = np.arange(self.num_subpopulations)\n",
    "        # permuted_subpopulation_indices = np.random.permutation(subpopulation_indices)\n",
    "        permuted_subpopulation_indices = subpopulation_indices\n",
    "        index_characters_to_subpopulations = []\n",
    "\n",
    "        if self.params['load_connections']:\n",
    "            # load connectivity: from characters to mini-subpopulations\n",
    "            \n",
    "            characters_to_subpopulations = load_input_encoding(self.data_path, fname)\n",
    "        else:\n",
    "            for char in self.vocabulary:\n",
    "                # randomly select a subset of mini-subpopulations for a character\n",
    "                characters_to_subpopulations[char] = permuted_subpopulation_indices[:self.params['L']]\n",
    "                # delete mini-subpopulations from the permuted_subpopulation_indices that are already selected\n",
    "                permuted_subpopulation_indices = permuted_subpopulation_indices[self.params['L']:]\n",
    "\n",
    "        return characters_to_subpopulations\n",
    "\n",
    "    def __set_min_synaptic_strength(self):\n",
    "        \"\"\"Set synaptic Wmin\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\nSet min synaptic strength ...')\n",
    "        connections = nest.GetConnections(synapse_model=self.params['syn_dict_ee']['synapse_model'])\n",
    "        print('\\nSet min synaptic strength .2..')\n",
    "\n",
    "        if \"stdsp\" in self.params['syn_dict_ee']['synapse_model']:\n",
    "            print('\\nSet min synaptic strength .3..')\n",
    "            #import pdb;pdb.set_trace()\n",
    "            if \"synapse_nestml\" in synapse_model_name:\n",
    "                connections.set({'permanence_min': connections.permanence})\n",
    "            else:\n",
    "                connections.set({'Pmin': connections.permanence})\n",
    "            \n",
    "            print('\\nSet min synaptic strength .3..')\n",
    "        else:\n",
    "            print('\\nSet min synaptic strength .4..')\n",
    "            connections.set({'Wmin': connections.weight})\n",
    "            print('\\nSet min synaptic strength .4..')\n",
    "\n",
    "    def save_connections(self, fname='ee_connections'):\n",
    "        \"\"\"Save connection matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        label: str\n",
    "            name of the stored file\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\nSave connections to ' + '%s/%s' % (self.data_path, fname) + '...')\n",
    "        connections_all = nest.GetConnections(synapse_model=self.params['syn_dict_ee']['synapse_model'])\n",
    "\n",
    "        connections = nest.GetStatus(connections_all, ['target', 'source', 'weight', 'permanence'])\n",
    "\n",
    "        np.save('%s/%s' % (self.data_path, fname), connections)\n",
    "\n",
    "    def __load_connections(self, label='ee_connections'):\n",
    "        \"\"\"Load connection matrix\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        label: str\n",
    "            name of the stored file\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.params['syn_dict_ee']['synapse_model'] != 'stdsp_synapse_rec', \"synapse model not tested yet\"\n",
    "\n",
    "        print('\\nLoad connections ...')\n",
    "        conns = np.load('%s/%s.npy' % (self.data_path, label))\n",
    "        conns_tg = [int(conn[0]) for conn in conns]\n",
    "        conns_src = [int(conn[1]) for conn in conns]\n",
    "        conns_weights = [conn[2] for conn in conns]\n",
    "\n",
    "        if \"stdsp\" in self.params['syn_dict_ee']['synapse_model']:\n",
    "            conns_perms = [conn[3] for conn in conns]\n",
    "\n",
    "        if self.params['evaluate_replay']:\n",
    "            syn_dict = {'receptor_type': 2,\n",
    "                        'delay': [self.params['syn_dict_ee']['delay']] * len(conns_weights),\n",
    "                        'weight': conns_weights}\n",
    "            nest.Connect(conns_src, conns_tg, 'one_to_one', syn_dict)\n",
    "        else:\n",
    "            syn_dict_ee = copy.deepcopy(self.params['syn_dict_ee'])\n",
    "\n",
    "            del syn_dict_ee['synapse_model']\n",
    "            del syn_dict_ee['weight']\n",
    "            del syn_dict_ee['receptor_type']\n",
    "            if \"stdsp\" in self.params['syn_dict_ee']['synapse_model']:\n",
    "                del syn_dict_ee['permanence']\n",
    "\n",
    "            nest.SetDefaults(self.params['syn_dict_ee']['synapse_model'], syn_dict_ee)\n",
    "\n",
    "            if \"stdsp\" in self.params['syn_dict_ee']['synapse_model']:\n",
    "                syn_dict = {'synapse_model': self.params['syn_dict_ee']['synapse_model'],\n",
    "                            'receptor_type': 2,\n",
    "                            'weight': conns_weights,\n",
    "                            'permanence': conns_perms}\n",
    "            else:\n",
    "                syn_dict = {'synapse_model': self.params['syn_dict_ee']['synapse_model'],\n",
    "                            'receptor_type': 2,\n",
    "                            'weight': conns_weights}\n",
    "\n",
    "            nest.Connect(conns_src, conns_tg, 'one_to_one', syn_dict)\n",
    "\n",
    "    def __get_time_constant_dendritic_rate(self, DeltaT=40., DeltaT_seq=100., calibration=100, target_firing_rate=1):\n",
    "        \"\"\"Compute time constant of the dendritic AP rate,\n",
    "\n",
    "        The time constant is set such that the rate captures how many dAPs a neuron generated\n",
    "        all along the period of a batch\n",
    "         \n",
    "        Parameters\n",
    "        ----------\n",
    "        calibration : float\n",
    "        target_firing_rate : float\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "           time constant of the dendritic AP rate\n",
    "        \"\"\"\n",
    "\n",
    "        t_exc = ((self.length_sequence-1) * DeltaT + DeltaT_seq + calibration) \\\n",
    "                * self.num_sequences\n",
    "\n",
    "        print(\"\\nDuration of a sequence set %d ms\" % t_exc)\n",
    "\n",
    "        return target_firing_rate * t_exc\n",
    "\n",
    "\n",
    "###########################################\n",
    "def load_input_encoding(path, fname):\n",
    "    \"\"\"Load input encoding: association between sequence element and subpopulations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "    fname: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    characters_to_subpopulations: dict\n",
    "    \"\"\"\n",
    "\n",
    "    characters_to_subpopulations = helper.load_data(path, fname)\n",
    "\n",
    "    return characters_to_subpopulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating code with NESTML\n",
    "\n",
    "We will take a simple current-based integrate-and-fire model with alpha-shaped postsynaptic response kernels (``iaf_psc_alpha``) as the basis for our modifications. First, let's take a look at this base neuron without any modifications.\n",
    "\n",
    "We will use a helper function to generate the C++ code for the models, build it as a NEST extension module, and load the module into the kernel. Because NEST does not support un- or reloading of modules at the time of writing, we implement a workaround that appends a unique number to the name of each generated model, for example, \"iaf_psc_alpha_3cc945f\". The resulting neuron model name is returned by the function, so we do not have to think about these internals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 36\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# codegen_opts = {\"neuron_synapse_pairs\": [{\"neuron\": \"iaf_psc_exp_dend\",\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                                           \"synapse\": \"third_factor_stdp_synapse\",\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#                                           \"post_ports\": [\"post_spikes\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# except:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m module_name, neuron_model_name, synapse_model_name \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mNESTCodeGeneratorUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_code_for\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/synapses/stdsp_synapse.nestml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDEBUG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mpost_ports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost_spikes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdAP_trace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdAP_trace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mcodegen_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneuron_parent_class_include\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchiving_node_ext.h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneuron_parent_class\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArchivingNodeExt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mmodule_name = \"nestml_54625aa90f64441d99f6349782e7215c_module\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mneuron_model_name = \"iaf_psc_exp_nonlineardendrite54625aa90f64441d99f6349782e7215c_neuron_nestml__with_stdsp54625aa90f64441d99f6349782e7215c_synapse_nestml\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03msynapse_model_name = \"stdsp54625aa90f64441d99f6349782e7215c_synapse_nestml__with_iaf_psc_exp_nonlineardendrite54625aa90f64441d99f6349782e7215c_neuron_nestml\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# JUST THE NEURON MODEL\u001b[39;00m\n",
      "File \u001b[0;32m~/julich/nestml-fork-clopath_synapse/nestml/pynestml/codegeneration/nest_code_generator_utils.py:88\u001b[0m, in \u001b[0;36mNESTCodeGeneratorUtils.generate_code_for\u001b[0;34m(cls, nestml_neuron_model, nestml_synapse_model, module_name, target_path, post_ports, mod_ports, codegen_opts, logging_level)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# read neuron model from file?\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m nestml_neuron_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.nestml\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nestml_neuron_model:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnestml_neuron_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m nestml_model_file:\n\u001b[1;32m     89\u001b[0m         nestml_neuron_model \u001b[38;5;241m=\u001b[39m nestml_model_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# update neuron model name inside the file\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/charl/julich/nestml-fork-clopath_synapse/nestml/pynestml/codegeneration/nest_code_generator_utils.py\u001b[0m(88)\u001b[0;36mgenerate_code_for\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     86 \u001b[0;31m        \u001b[0;31m# read neuron model from file?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnestml_neuron_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\".nestml\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnestml_neuron_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 88 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnestml_neuron_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnestml_model_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     89 \u001b[0;31m                \u001b[0mnestml_neuron_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnestml_model_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%pdb\n",
    "# codegen_opts = {\"neuron_synapse_pairs\": [{\"neuron\": \"iaf_psc_exp_dend\",\n",
    "#                                           \"synapse\": \"third_factor_stdp_synapse\",\n",
    "#                                           \"post_ports\": [\"post_spikes\",\n",
    "#       http://localhost:8888/notebooks/doc/tutorials/sequences/sequences.ipynb#            \n",
    "#[\"I_post_dend\", \"I_dend\"]]}]}\n",
    "\n",
    "# if not NESTTools.detect_nest_version().startswith(\"v2\"):\n",
    "#     codegen_opts[\"neuron_parent_class\"] = \"StructuralPlasticityNode\"\n",
    "#     codegen_opts[\"neuron_parent_class_include\"] = \"structural_plasticity_node.h\"\n",
    "\n",
    "# generate the \"jit\" model (co-generated neuron and synapse), that does not rely on ArchivingNode\n",
    "# files = [os.path.join(\"models\", \"neurons\", \"iaf_psc_exp_dend_neuron.nestml\"),\n",
    "#          os.path.join(\"models\", \"synapses\", \"third_factor_stdp_synapse.nestml\")]\n",
    "# input_path = [os.path.realpath(os.path.join(os.path.dirname(__file__), os.path.join(\n",
    "#     os.pardir, os.pardir, s))) for s in files]\n",
    "# generate_nest_target(input_path=input_path,\n",
    "#                      target_path=\"/tmp/nestml-jit\",\n",
    "#                      logging_level=\"INFO\",\n",
    "#                      module_name=\"nestml_jit_module\",\n",
    "#                      codegen_opts=codegen_opts)\n",
    "#nest.Install(\"nestml_jit_module\")\n",
    "\n",
    "# generate and build code\n",
    "\n",
    "\n",
    "# ------------ VERSIONS INHERITING FROM ARCHIVINGNODEEXT\n",
    "# try:\n",
    "# module_name, neuron_model_name, synapse_model_name = \\\n",
    "#     NESTCodeGeneratorUtils.generate_code_for(\"../../../doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml\",\n",
    "#                                              \"../../../models/synapses/stdsp_synapse.nestml\",\n",
    "#                                              logging_level=\"DEBUG\",\n",
    "#                                              post_ports=[\"post_spikes\", [\"dAP_trace\", \"dAP_trace\"]],\n",
    "#                                              codegen_opts={\"neuron_parent_class_include\": \"archiving_node_ext.h\",    \"neuron_parent_class\": \"ArchivingNodeExt\"})\n",
    "\n",
    "# except:\n",
    "# module_name, neuron_model_name, synapse_model_name = \\\n",
    "#     NESTCodeGeneratorUtils.generate_code_for(\"doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml\",\n",
    "#                                              \"models/synapses/stdsp_synapse.nestml\",\n",
    "#                                              logging_level=\"DEBUG\",\n",
    "#                                              post_ports=[\"post_spikes\", [\"dAP_trace\", \"dAP_trace\"]],\n",
    "#                                              codegen_opts={\"neuron_parent_class_include\": \"archiving_node_ext.h\",    \"neuron_parent_class\": \"ArchivingNodeExt\"})\n",
    "\n",
    "\n",
    "module_name, neuron_model_name, synapse_model_name = \\\n",
    "    NESTCodeGeneratorUtils.generate_code_for(\"doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml\",\n",
    "                                             \"models/synapses/stdsp_synapse.nestml\",\n",
    "                                             logging_level=\"DEBUG\",\n",
    "                                             post_ports=[\"post_spikes\", [\"dAP_trace\", \"dAP_trace\"]])\n",
    "\n",
    "\n",
    "print(\"module name: \" + module_name)\n",
    "print(\"neuron model name: \" + neuron_model_name)\n",
    "print(\"synapse model name: \" + synapse_model_name)\n",
    "\n",
    "\"\"\"\n",
    "module_name = \"nestml_54625aa90f64441d99f6349782e7215c_module\"\n",
    "neuron_model_name = \"iaf_psc_exp_nonlineardendrite54625aa90f64441d99f6349782e7215c_neuron_nestml__with_stdsp54625aa90f64441d99f6349782e7215c_synapse_nestml\"\n",
    "synapse_model_name = \"stdsp54625aa90f64441d99f6349782e7215c_synapse_nestml__with_iaf_psc_exp_nonlineardendrite54625aa90f64441d99f6349782e7215c_neuron_nestml\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# JUST THE NEURON MODEL\n",
    "\"\"\"\n",
    "module_name, neuron_model_name = \\\n",
    "    NESTCodeGeneratorUtils.generate_code_for(\"doc/tutorials/sequences/iaf_psc_exp_nonlineardendrite_neuron.nestml\",\n",
    "                                             logging_level=\"DEBUG\",\n",
    "                                            codegen_opts = {\n",
    "    \"neuron_parent_class_include\": \"archiving_node_ext.h\",\n",
    "    \"neuron_parent_class\": \"ArchivingNodeExt\",\n",
    "            }\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# LASTLOG: using a manually modified neuron model (because it needs the get_dendritic_firing_rate() method)\n",
    "# in combination with the NEST built-in stdsp_synapse\n",
    "\n",
    "# run as LD_LIBRARY_PATH=/tmp/nestml_target_olo6bfq7:/home/charl/julich/nest-simulator-install/lib/nest:/home/charl/julich/nest-simulator-install/lib/python3.11/site-packages/nest:/home/charl/julich/nest-simulator-install/pynest PYTHONPATH=/home/charl/julich/nest-simulator-install/lib/python3.11/site-packages:`pwd`:/home/charl/julich/ode-toolbox-upstream/ode-toolbox/ ipython3 -i doc/tutorials/sequences/sequences.ipynb\n",
    "\n",
    "neuron_model_name = \"iaf_psc_exp_nonlineardendrite609ae82391c641f7ad702d2c8ed1ea9f_neuron_nestml\"\n",
    "module_name = \"nestml_609ae82391c641f7ad702d2c8ed1ea9f_module\"\n",
    "\n",
    "synapse_model_name = \"stdsp_synapse\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the NESTML model is ready to be used in a simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psp_max_2_psc_max(psp_max, tau_m, tau_s, R_m):\n",
    "    \"\"\"Compute the PSC amplitude (pA) injected to get a certain PSP maximum (mV) for LIF with exponential PSCs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    psp_max: float\n",
    "             Maximum postsynaptic pontential\n",
    "    tau_m:   float\n",
    "             Membrane time constant (ms).\n",
    "    tau_s:   float\n",
    "             Synaptic time constant (ms).\n",
    "    R_m:     float\n",
    "             Membrane resistance (Gohm).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        PSC amplitude (pA).\n",
    "    \"\"\"\n",
    "\n",
    "    return psp_max / (\n",
    "            R_m * tau_s / (tau_s - tau_m) * (\n",
    "            (tau_m / tau_s) ** (-tau_m / (tau_m - tau_s)) -\n",
    "            (tau_m / tau_s) ** (-tau_s / (tau_m - tau_s))\n",
    "    )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: dAP generation in the neuron model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_active_dendrite_parameters():\n",
    "    p = para.ParameterSpace({})\n",
    "    \n",
    "    DELAY = 0.1\n",
    "    \n",
    "    p['dt'] = 0.1                                  # simulation time resolution (ms)\n",
    "    p['print_simulation_progress'] = False         # print the time progress.\n",
    "    \n",
    "    \n",
    "    # data path dict\n",
    "    p['data_path'] = {}\n",
    "    p['data_path']['data_root_path'] = 'data'\n",
    "    p['data_path']['project_name'] = 'sequence_learning_performance'\n",
    "    p['data_path']['parameterspace_label'] = 'effect_dAP_firing_times'\n",
    "    \n",
    "    # neuron parameters of the excitatory neurons\n",
    "    p['soma_model'] = neuron_model_name\n",
    "    p['soma_params'] = {}\n",
    "    p['soma_params']['C_m'] = 250.        # membrane capacitance (pF)\n",
    "    p['soma_params']['E_L'] = 0.          # resting membrane potential (mV)\n",
    "    # p['soma_params']['I_e'] = 0.        # external DC currents (pA)\n",
    "    p['soma_params']['V_m'] = 0.          # initial potential (mV)\n",
    "    p['soma_params']['V_reset'] = 0.      # reset potential (mV)\n",
    "    p['soma_params']['V_th'] = 20.        # spike threshold (mV)\n",
    "    p['soma_params']['t_ref'] = 10.       # refractory period\n",
    "    p['soma_params']['tau_m'] = 10.       # membrane time constant (ms)\n",
    "    p['soma_params']['tau_syn1'] = 2.     # synaptic time constant: external input (receptor 1)\n",
    "    p['soma_params']['tau_syn2'] = 5.     # synaptic time constant: dendrtic input (receptor 2)\n",
    "    p['soma_params']['tau_syn3'] = 1.     # synaptic time constant: inhibitory input (receptor 3)\n",
    "    # dendritic action potential\n",
    "    p['soma_params']['I_p'] = 200. # current clamp value for I_dAP during a dendritic action potenti\n",
    "    p['soma_params']['tau_dAP'] = 60.       # time window over which the dendritic current clamp is active\n",
    "    p['soma_params']['theta_dAP'] = 59.        # current threshold for a dendritic action potential\n",
    "    \n",
    "    p['soma_params']['I_dend_incr'] = 2.71 / (p['soma_params']['tau_syn2'])\n",
    "    \n",
    "    \n",
    "    p['fixed_somatic_delay'] = 2          # this is an approximate time of how long it takes the soma to fire\n",
    "                                          # upon receiving an external stimulus \n",
    "    \n",
    "    # neuron parameters for the inhibitory neuron\n",
    "    p['inhibit_model'] = 'iaf_psc_exp'\n",
    "    p['inhibit_params'] = {}\n",
    "    p['inhibit_params']['C_m'] = 250.         # membrane capacitance (pF)\n",
    "    p['inhibit_params']['E_L'] = 0.           # resting membrane potential (mV)\n",
    "    p['inhibit_params']['I_e'] = 0.           # external DC currents (pA)\n",
    "    p['inhibit_params']['V_m'] = 0.           # initial potential (mV)\n",
    "    p['inhibit_params']['V_reset'] = 0.       # reset potential (mV)\n",
    "    p['inhibit_params']['V_th'] = 15.         # spike threshold (mV)\n",
    "    p['inhibit_params']['t_ref'] = 2.0        # refractory period\n",
    "    p['inhibit_params']['tau_m'] = 5.         # membrane time constant (ms)\n",
    "    p['inhibit_params']['tau_syn_ex'] = .5    # synaptic time constant of an excitatory input (ms) \n",
    "    p['inhibit_params']['tau_syn_in'] = 1.65  # synaptic time constant of an inhibitory input (ms)\n",
    "    \n",
    "    # synaptic parameters\n",
    "    p['J_EX_psp'] = 1.1 * p['soma_params']['V_th']     # somatic PSP as a response to an external input\n",
    "    p['J_IE_psp'] = 1.2 * p['inhibit_params']['V_th']  # inhibitory PSP as a response to an input from E neuron\n",
    "    p['J_EI_psp'] = -2 * p['soma_params']['V_th']      # somatic PSP as a response to an inhibitory input\n",
    "    p['convergence'] = 5\n",
    "    p['pattern_size'] = 20\n",
    "    \n",
    "    # parameters for ee synapses (stdsp)\n",
    "    p['syn_dict_ee'] = {}\n",
    "    p['p_min'] = 0.\n",
    "    p['p_max'] = 8.\n",
    "    p['calibration'] = 40.\n",
    "    p['syn_dict_ee']['weight'] = 0.01                    # synaptic weight\n",
    "    p['syn_dict_ee']['synapse_model'] = synapse_model_name  # synapse model\n",
    "    p['syn_dict_ee']['permanence_threshold'] = 10.                    # synapse maturity threshold\n",
    "    p['syn_dict_ee']['tau_pre_trace'] = 20.                   # plasticity time constant (potentiation)\n",
    "    p['syn_dict_ee']['delay'] = 2.                       # dendritic delay \n",
    "    p['syn_dict_ee']['receptor_type'] = 2                # receptor corresponding to the dendritic input\n",
    "    p['syn_dict_ee']['lambda_plus'] = 0.05 #0.1                     # potentiation rate\n",
    "    p['syn_dict_ee']['zt'] = 1.                          # target dAP trace [pA]\n",
    "    p['syn_dict_ee']['lambda_h'] = 0.01                        # homeostasis rate\n",
    "    p['syn_dict_ee']['Wmax'] = 1.1 * p['soma_params']['theta_dAP'] / p['convergence']   # Maximum allowed weight\n",
    "\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['permanence_max'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['permanence_min'] = 1.                        # Minimum allowed permanence\n",
    "    else:\n",
    "        p['syn_dict_ee']['Pmax'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['Pmin'] = 1.                        # Minimum allowed permanence\n",
    "    p['syn_dict_ee']['lambda_minus'] = 0.004\n",
    "    \n",
    "    # parameters of EX synapses (external to soma of E neurons)\n",
    "    p['conn_dict_ex'] = {}\n",
    "    p['syn_dict_ex'] = {}\n",
    "    p['syn_dict_ex']['receptor_type'] = 1                    # receptor corresponding to external input\n",
    "    p['syn_dict_ex']['delay'] = DELAY                        # dendritic delay\n",
    "    p['conn_dict_ex']['rule'] = 'all_to_all'                 # connection rule\n",
    "    \n",
    "    # parameters of EdX synapses (external to dendrite of E neurons) \n",
    "    p['conn_dict_edx'] = {}\n",
    "    p['syn_dict_edx'] = {}\n",
    "    p['syn_dict_edx']['receptor_type'] = 2                    # receptor corresponding to the dendritic input\n",
    "    p['syn_dict_edx']['delay'] = DELAY                        # dendritic delay\n",
    "    p['syn_dict_edx']['weight'] = 1.4 * p['soma_params']['theta_dAP']\n",
    "    p['conn_dict_edx']['rule'] = 'fixed_outdegree'            # connection rule\n",
    "    p['conn_dict_edx']['outdegree'] = p['pattern_size'] + 1   # outdegree\n",
    "    \n",
    "    # parameters for IE synapses \n",
    "    p['syn_dict_ie'] = {}\n",
    "    p['conn_dict_ie'] = {}\n",
    "    p['syn_dict_ie']['synapse_model'] = 'static_synapse'     # synapse model\n",
    "    p['syn_dict_ie']['delay'] = DELAY                        # dendritic delay\n",
    "    p['conn_dict_ie']['rule'] = 'fixed_indegree'             # connection rule\n",
    "    p['conn_dict_ie']['indegree'] = 5                        # indegree \n",
    "    \n",
    "    # parameters for EI synapses\n",
    "    p['syn_dict_ei'] = {}\n",
    "    p['conn_dict_ei'] = {}\n",
    "    p['syn_dict_ei']['synapse_model'] = 'static_synapse'     # synapse model\n",
    "    p['syn_dict_ei']['delay'] = DELAY                        # dendritic delay\n",
    "    p['syn_dict_ei']['receptor_type'] = 3                    # receptor corresponding to the inhibitory input  \n",
    "    p['conn_dict_ei']['rule'] = 'fixed_indegree'             # connection rule\n",
    "    p['conn_dict_ei']['indegree'] = 20                       # indegree\n",
    "    \n",
    "    \n",
    "    p['R_m_soma'] = p['soma_params']['tau_m'] / p['soma_params']['C_m']\n",
    "    p['R_m_inhibit'] = p['inhibit_params']['tau_m'] / p['inhibit_params']['C_m']\n",
    "    p['syn_dict_ex']['weight'] = psp_max_2_psc_max(p['J_EX_psp'], \n",
    "                                                               p['soma_params']['tau_m'], \n",
    "                                                               p['soma_params']['tau_syn1'], \n",
    "                                                               p['R_m_soma'])\n",
    "    p['syn_dict_ie']['weight'] = psp_max_2_psc_max(p['J_IE_psp'], \n",
    "                                                               p['inhibit_params']['tau_m'], \n",
    "                                                               p['inhibit_params']['tau_syn_ex'], \n",
    "                                                               p['R_m_inhibit'])\n",
    "    p['syn_dict_ei']['weight'] = psp_max_2_psc_max(p['J_EI_psp'], \n",
    "                                                               p['soma_params']['tau_m'], \n",
    "                                                               p['soma_params']['tau_syn3'], \n",
    "                                                               p['R_m_soma'])\n",
    "\n",
    "    \n",
    "    p['soma_excitation_time'] = 25.\n",
    "    p['dendrite_excitation_time'] = 3.\n",
    "\n",
    "    return p\n",
    "\n",
    "p = create_active_dendrite_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_psc_test(params):\n",
    "    print(\"Running psc test simulation!\")\n",
    "    # init kernel\n",
    "    seed = 1\n",
    "    nest.ResetKernel()\n",
    "    nest.Install(module_name)\n",
    "    nest.set_verbosity(\"M_ALL\")\n",
    "    nest.SetKernelStatus({\n",
    "        'resolution': params['dt'],\n",
    "        'print_time': params['print_simulation_progress'],\n",
    "        'local_num_threads': n_threads,\n",
    "        'rng_seed': seed\n",
    "    })\n",
    "\n",
    "    #############################\n",
    "    # create and connect neurons\n",
    "    # ---------------------------\n",
    "\n",
    "    # create excitatory population\n",
    "    exc_neuron = nest.Create(params['soma_model'], params=params['soma_params'])\n",
    "\n",
    "    ######################\n",
    "    # Input stream/stimuli\n",
    "    #---------------------\n",
    "    input_excitation = nest.Create('spike_generator', params={'spike_times':[10.]})\n",
    "    dendrite_excitation_1 = nest.Create('spike_generator', params={'spike_times':[50., 140.], \"spike_weights\": [1., 100.]})\n",
    "    dendrite_excitation_2 = nest.Create('spike_generator', params={'spike_times':[90.]})\n",
    "\n",
    "    nest.Connect(input_excitation, exc_neuron, syn_spec={'receptor_type': 1, \n",
    "                                                         'weight': 10000., \n",
    "                                                         'delay': 1.})\n",
    "\n",
    "    nest.Connect(dendrite_excitation_1, exc_neuron, syn_spec={'receptor_type': 2, \n",
    "                                                         'weight': 1., \n",
    "                                                         'delay': 1.})\n",
    "\n",
    "    nest.Connect(dendrite_excitation_2, exc_neuron, syn_spec={'receptor_type': 3, \n",
    "                                                         'weight': 100., \n",
    "                                                         'delay': 1.})\n",
    "\n",
    "    mm = nest.Create('multimeter', params={'record_from': ['V_m', 'active_dendrite_readout', 'I_dend'], 'interval': 0.1})\n",
    "    nest.Connect(mm, exc_neuron)\n",
    "\n",
    "    # record spikes\n",
    "    sd = nest.Create('spike_recorder')\n",
    "    nest.Connect(exc_neuron, sd)\n",
    "\n",
    "    print('### simulating network')\n",
    "    nest.Prepare()\n",
    "    nest.Run(250.)\n",
    "\n",
    "    times = nest.GetStatus(mm)[0]['events'][\"times\"] \n",
    "    voltage_soma = nest.GetStatus(mm)[0]['events']['V_m']  \n",
    "    active_dendrite_readout = nest.GetStatus(mm)[0]['events']['active_dendrite_readout']\n",
    "    I_dend = nest.GetStatus(mm)[0]['events']['I_dend']\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=3, dpi=600, figsize=(8,6))\n",
    "    ax[0].plot(times, voltage_soma, label=\"V_m\")\n",
    "    ax[1].plot(times, active_dendrite_readout, label=\"active dend\")\n",
    "    ax[2].plot(times, I_dend, label=\"I_dend\")\n",
    "    for _ax in ax:\n",
    "        _ax.legend()\n",
    "\n",
    "    fig.savefig(\"/tmp/psc_test.png\")\n",
    "\n",
    "\n",
    "\n",
    "#import sys;sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_dendrite_simulation(params):\n",
    "    print(\"Running active dendrite simulation!\")\n",
    "    data = {}\n",
    "    for i, name in enumerate(['ff', 'dendrite', 'ff_dendrite']): \n",
    "        print(\"Running experiment type: \" + name)\n",
    "        # init kernel\n",
    "        seed = 1\n",
    "        nest.ResetKernel()\n",
    "        nest.Install(module_name)\n",
    "        nest.set_verbosity(\"M_ALL\")\n",
    "        nest.SetKernelStatus({\n",
    "            'resolution': params['dt'],\n",
    "            'print_time': params['print_simulation_progress'],\n",
    "            'local_num_threads': n_threads,\n",
    "            'rng_seed': seed\n",
    "        })\n",
    "    \n",
    "        data[name] = {}\n",
    "    \n",
    "        #############################\n",
    "        # create and connect neurons\n",
    "        # ---------------------------\n",
    "    \n",
    "        # create excitatory population\n",
    "        exc_neuron = nest.Create(params['soma_model'], params=params['soma_params'])\n",
    "    \n",
    "        # create inhibitory population\n",
    "        inh_neuron = nest.Create(params['inhibit_model'], params=params['inhibit_params'])\n",
    "    \n",
    "        # connect inhibition\n",
    "        nest.Connect(exc_neuron, inh_neuron, syn_spec=params['syn_dict_ie'])\n",
    "        nest.Connect(inh_neuron, exc_neuron, syn_spec=params['syn_dict_ei'])\n",
    "    \n",
    "        ######################\n",
    "        # Input stream/stimuli\n",
    "        #---------------------\n",
    "        input_excitation = nest.Create('spike_generator', params={'spike_times':[params['soma_excitation_time']]})\n",
    "        dendrite_excitation_1 = nest.Create('spike_generator', params={'spike_times':[params['dendrite_excitation_time']]})\n",
    "        #dendrite_excitation_2 = nest.Create('spike_generator', params={'spike_times':[7.]})\n",
    "        inhibition_excitation = nest.Create('spike_generator', params={'spike_times':[10.]})\n",
    "    \n",
    "        # excitation soma feedforward\n",
    "        if name == 'ff' or name == 'ff_dendrite':\n",
    "            nest.Connect(input_excitation, exc_neuron, syn_spec={'receptor_type': 1, \n",
    "                                                                 'weight': params['syn_dict_ex']['weight'], \n",
    "                                                                 'delay': params['syn_dict_ex']['delay']})\n",
    "\n",
    "        # excitation dendrite \n",
    "        if name == 'dendrite' or name == 'ff_dendrite':\n",
    "            nest.Connect(dendrite_excitation_1, exc_neuron, syn_spec={'receptor_type': 2, \n",
    "                                                                      'weight': params['syn_dict_edx']['weight'], \n",
    "                                                                      'delay': params['syn_dict_edx']['delay']})\n",
    "    \n",
    "        # record voltage inhibitory neuron \n",
    "        vm_inh = nest.Create('voltmeter', params={'record_from': ['V_m'], 'interval': 0.1})\n",
    "        nest.Connect(vm_inh, inh_neuron)\n",
    "    \n",
    "        # record voltage soma\n",
    "        vm_exc = nest.Create('voltmeter', params={'record_from': ['V_m'], 'interval': 0.1})\n",
    "        nest.Connect(vm_exc, exc_neuron)\n",
    "    \n",
    "        active_dendrite_exc_mm = nest.Create('multimeter', params={'record_from': ['active_dendrite_readout', 'I_dend'], 'interval': 0.1})\n",
    "        nest.Connect(active_dendrite_exc_mm, exc_neuron)\n",
    "    \n",
    "        # record spikes\n",
    "        sd = nest.Create('spike_recorder')\n",
    "        nest.Connect(exc_neuron, sd)\n",
    "    \n",
    "        # record inh spikes\n",
    "        sd_inh = nest.Create('spike_recorder')\n",
    "        nest.Connect(inh_neuron, sd_inh)\n",
    "    \n",
    "        print('### simulating network')\n",
    "        #nest.Simulate(100.)\n",
    "        nest.Prepare()\n",
    "        nest.Run(100.)\n",
    "    \n",
    "        voltage_soma = nest.GetStatus(vm_exc)[0]['events']  \n",
    "        active_dendrite = nest.GetStatus(active_dendrite_exc_mm)[0]['events']\n",
    "        voltage_inhibit = nest.GetStatus(vm_inh)[0]['events'] \n",
    "        spikes_soma = nest.GetStatus(sd)[0]['events'] \n",
    "        spikes_inh = nest.GetStatus(sd_inh)[0]['events'] \n",
    "    \n",
    "        data[name]['exc'] = voltage_soma \n",
    "        data[name]['exc_active_dendrite'] = active_dendrite \n",
    "        data[name]['inh'] = voltage_inhibit\n",
    "        data[name]['spikes_exc'] = spikes_soma\n",
    "        data[name]['spikes_inh'] = spikes_inh\n",
    "\n",
    "    return data\n",
    "\n",
    "data = run_active_dendrite_simulation(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_active_dendrite_simulation(params, data):\n",
    "    \n",
    "    \n",
    "    def position_excitation_arrows(ax, soma_time, dendrite_time):\n",
    "    \n",
    "        arrow_width = 1.8\n",
    "        arrow_height = 1.8\n",
    "        y = -2.3\n",
    "        \n",
    "        # plot excitation arrows for panel A\n",
    "        x = soma_time - arrow_width/2 \n",
    "        pos = [x, y]\n",
    "        X = np.array([pos, [pos[0]+arrow_width, pos[1]], [pos[0]+arrow_width/2, pos[1]+arrow_height]])\n",
    "        t1 = plt.Polygon(X, color=color_somatic_input)\n",
    "        ax[0].add_patch(t1)\n",
    "    \n",
    "        # plot excitation arrows for panel B\n",
    "        x = dendrite_time - arrow_width/2 \n",
    "        pos = [x, y]\n",
    "        X = np.array([pos, [pos[0]+arrow_width, pos[1]], [pos[0]+arrow_width/2, pos[1]+arrow_height]])\n",
    "        t1 = plt.Polygon(X, color=color_dAP_input)\n",
    "        ax[1].add_patch(t1)\n",
    "    \n",
    "        # plot excitation arrows for panel C\n",
    "        x = dendrite_time - arrow_width/2 \n",
    "        pos = [x, y]\n",
    "        X = np.array([pos, [pos[0]+arrow_width, pos[1]], [pos[0]+arrow_width/2, pos[1]+arrow_height]])\n",
    "        t1 = plt.Polygon(X, color=color_dAP_input)\n",
    "        ax[2].add_patch(t1)\n",
    "    \n",
    "        x = soma_time - arrow_width/2 \n",
    "        pos = [x, y]\n",
    "        X = np.array([pos, [pos[0]+arrow_width, pos[1]], [pos[0]+arrow_width/2, pos[1]+arrow_height]])\n",
    "        t1 = plt.Polygon(X, color=color_somatic_input)\n",
    "        ax[2].add_patch(t1)\n",
    "    \n",
    "    \n",
    "    color_dAP_input = '#8e7c42ff'\n",
    "    #color_somatic_input = '#0000ffff'\n",
    "    color_somatic_input = '#4581a7ff'\n",
    "    color_soma = '#000000ff'\n",
    "    color_dAP = '#00B4BE' \n",
    "    color_inhibit = '#808080ff'  \n",
    "    color_hrl = 'black'\n",
    "    \n",
    "    #color_somatic_spike = '#ff0000ff'\n",
    "    color_somatic_spike = color_soma\n",
    "    color_inh_spike = color_inhibit\n",
    "    ms_spike = 7\n",
    "    mew_spike = 1.5\n",
    "    lw_vtheta = 0.5\n",
    "    lw_dAP = 1.5\n",
    "    lw_s = 1.5\n",
    "    lw_i = 1.5\n",
    "    \n",
    "    # plot settings \n",
    "    fig_size = (6., 5)\n",
    "    ymin = -4\n",
    "    ymax = params['soma_params']['V_th'] + 4\n",
    "    xmin = 0  \n",
    "    xmax = 85\n",
    "    label_pos = (-0.18, 1.)\n",
    "    panel_labels = ['A', 'B', 'C']\n",
    "    v_th=params['soma_params']['V_th'] \n",
    "    time_dAP = 10\n",
    "    \n",
    "    # set up the figure frame\n",
    "    fig = plt.figure()\n",
    "    gs = mpl.gridspec.GridSpec(5, 1, height_ratios=[15,15,15,5,6], bottom=0.1, right=0.95, top=0.93, wspace=0., hspace=0.1)\n",
    "    left, bottom, width, height = [0.4, 0.1, 0.2, 0.2]\n",
    "    axes = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, name in enumerate(['ff', 'dendrite', 'ff_dendrite']):\n",
    "    \n",
    "        #ax = fig.add_subplot(gs[i,0])\n",
    "        ax = plt.subplot(gs[i,0])\n",
    "        ax.text(label_pos[0], label_pos[1], panel_labels[i], transform=ax.transAxes, horizontalalignment='center', verticalalignment='center', size=10, weight='bold')\n",
    "        ax.plot(data[name]['exc']['times'], data[name]['exc']['V_m'], lw=lw_s, color=color_soma, zorder=2, label='excitatory neuron')  \n",
    "        \n",
    "        \n",
    "        ax.plot(data[name]['exc_active_dendrite']['times'], data[name]['exc_active_dendrite']['active_dendrite_readout'], lw=lw_s, color=color_dAP)  \n",
    "        \n",
    "        ax_ = ax.twinx()\n",
    "        ax_.plot(data[name]['exc_active_dendrite']['times'], data[name]['exc_active_dendrite']['I_dend'], lw=lw_s, color=\"red\", label=\"I_dend\")  \n",
    "        ax_.plot((0., np.amax(data[name]['exc_active_dendrite']['times'])), 2*[p['soma_params']['theta_dAP']], c=\"red\", linestyle=':')\n",
    "                 \n",
    "        ax.plot(data[name]['spikes_exc']['times'], (v_th+2)*np.ones(len(data[name]['spikes_exc']['times'])), '|', c=color_somatic_spike, ms=ms_spike, mew=mew_spike)\n",
    "        ax.plot(data[name]['spikes_inh']['times'], (v_th+2)*np.ones(len(data[name]['spikes_inh']['times'])), '|', c=color_inh_spike, ms=ms_spike, mew=mew_spike)\n",
    "        ax.legend()\n",
    "     \n",
    "        # add dendritic action potential bar manually\n",
    "        if name == 'dendrite': \n",
    "            ax.hlines(v_th+2, time_dAP, time_dAP+params['soma_params']['tau_dAP'], lw=lw_dAP, color=color_dAP)\n",
    "    \n",
    "        if name == 'ff_dendrite': \n",
    "            ax.hlines(v_th+2, time_dAP, data[name]['spikes_exc']['times'][0], lw=lw_dAP, color=color_dAP)\n",
    "    \n",
    "        # clamp voltage if doesn't reach the firing threshold\n",
    "        if name == 'ff' or name == 'ff_dendrite': \n",
    "            max_volt = max(data[name]['inh']['V_m']) \n",
    "            max_volt_ind = np.where(data[name]['inh']['V_m']==max_volt)[0]\n",
    "            data[name]['inh']['V_m'][max_volt_ind] = 20\n",
    "    \n",
    "        ax.plot(data[name]['inh']['times'], data[name]['inh']['V_m'], lw=lw_i, color=color_inhibit, zorder=1, label='inhibitory neuron') \n",
    "        ax.set_ylim([ymin, ymax])\n",
    "        ax.set_xlim([xmin, xmax])\n",
    "        ax.hlines(v_th, xmin, xmax, lw=lw_vtheta, color=color_hrl, linestyle='--')\n",
    "    \n",
    "        axes.append(ax)\n",
    "    \n",
    "    axes[1].set_ylabel('membrane potential (mV)')\n",
    "    \n",
    "    # set position of arrows\n",
    "    position_excitation_arrows(axes, p['soma_excitation_time'], p['dendrite_excitation_time'])\n",
    "    \n",
    "    axes[0].legend(loc='center right')\n",
    "    axes[0].set_yticklabels([])\n",
    "    axes[0].set_xticklabels([])\n",
    "    axes[1].set_xticklabels([])\n",
    "    axes[2].set_yticklabels([])\n",
    "    axes[2].set_xlabel('time (ms)')\n",
    "    \n",
    "    ########################################\n",
    "    # plt spikes of A and B\n",
    "    # --------------------------------------\n",
    "    ax = fig.add_subplot(gs[i+1,0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    ax = plt.subplot(gs[i+2,0])\n",
    "    ax.text(label_pos[0], label_pos[1], 'D', transform=ax.transAxes, horizontalalignment='center', verticalalignment='center', size=10, weight='bold')\n",
    "    \n",
    "    xmin_d=25.6\n",
    "    xmax_d=29\n",
    "    \n",
    "    ymin_d=0\n",
    "    ymax_d=10\n",
    "    \n",
    "    name = 'ff'\n",
    "    ax.plot(data[name]['spikes_exc']['times'], (3*ymax_d/4)*np.ones(len(data[name]['spikes_exc']['times'])), '|', c=color_somatic_spike, ms=ms_spike, mew=mew_spike)\n",
    "    ax.plot(data[name]['spikes_inh']['times'], (3*ymax_d/4)*np.ones(len(data[name]['spikes_inh']['times'])), '|', c=color_inh_spike, ms=ms_spike, mew=mew_spike)\n",
    "    \n",
    "    name = 'ff_dendrite'\n",
    "    ax.plot(data[name]['spikes_exc']['times'], (ymax_d/4)*np.ones(len(data[name]['spikes_exc']['times'])), '|', c=color_somatic_spike, ms=ms_spike, mew=mew_spike)\n",
    "    ax.plot(data[name]['spikes_inh']['times'], (ymax_d/4)*np.ones(len(data[name]['spikes_inh']['times'])), '|', c=color_inh_spike, ms=ms_spike, mew=mew_spike)\n",
    "    ax.hlines(ymax_d/2, xmin, xmax, lw=0.5, color=color_hrl, linestyles='solid')\n",
    "    \n",
    "    ax.set_yticklabels([])\n",
    "    ax.tick_params(left=False)\n",
    "    ax.set_ylim([ymin_d, ymax_d])\n",
    "    ax.set_xlim([xmin_d, xmax_d])\n",
    "    ax.set_xlabel('time (ms)')\n",
    "    \n",
    "    ax.text(xmin_d+0.05, (3*ymax_d/4)-1, 'A', size=8, weight='bold')\n",
    "    ax.text(xmin_d+0.05, (ymax_d/4)-1, 'C', size=8, weight='bold')\n",
    "    \n",
    "    ############################################################\n",
    "    # add lines between the subplots showing the zoomed in area\n",
    "    # ----------------------------------------------------------\n",
    "    xy_C = (xmin_d,ymin)\n",
    "    xy_D = (xmin_d,ymax_d)\n",
    "    con = mpl.patches.ConnectionPatch(xyA=xy_C, xyB=xy_D, coordsA='data', coordsB='data', axesA=axes[-1], axesB=ax, color='grey', linestyle='dotted')\n",
    "    ax.add_artist(con)\n",
    "    \n",
    "    xy_C = (xmax_d,ymin)\n",
    "    xy_D = (xmax_d,ymax_d)\n",
    "    con = mpl.patches.ConnectionPatch(xyA=xy_C, xyB=xy_D, coordsA='data', coordsB='data', axesA=axes[-1], axesB=ax, color='grey', linestyle='dotted')\n",
    "    ax.add_artist(con)\n",
    "    \n",
    "    plt.savefig(\"/tmp/sequences1.png\")\n",
    "\n",
    "plot_active_dendrite_simulation(p, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: synaptic plasticity dependence on dAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stdsp_dependence_on_third_factor_parameters():\n",
    "    DELAY = 0.1\n",
    "    \n",
    "    p = para.ParameterSpace({})\n",
    "    \n",
    "    p['dt'] = 0.1                                  # simulation time resolution (ms)\n",
    "    p['print_simulation_progress'] = True         # print the time progress.\n",
    "    \n",
    "    # neuron parameters of the excitatory neurons\n",
    "    p['soma_model'] = neuron_model_name\n",
    "    p['soma_params'] = {}\n",
    "    p['soma_params']['C_m'] = 250.        # membrane capacitance (pF)\n",
    "    p['soma_params']['E_L'] = 0.          # resting membrane potential (mV)\n",
    "    # p['soma_params']['I_e'] = 0.        # external DC currents (pA)\n",
    "    p['soma_params']['V_m'] = 0.          # initial potential (mV)\n",
    "    p['soma_params']['V_reset'] = 0.      # reset potential (mV)\n",
    "    p['soma_params']['V_th'] = 20.        # spike threshold (mV)\n",
    "    p['soma_params']['t_ref'] = 10.       # refractory period\n",
    "    p['soma_params']['tau_m'] = 10.       # membrane time constant (ms)\n",
    "    p['soma_params']['tau_syn1'] = 2.     # synaptic time constant: external input (receptor 1)\n",
    "    p['soma_params']['tau_syn2'] = 5.     # synaptic time constant: dendrtic input (receptor 2)\n",
    "    p['soma_params']['tau_syn3'] = 1.     # synaptic time constant: inhibitory input (receptor 3)\n",
    "    # dendritic action potential\n",
    "    p['soma_params']['I_p'] = 200. # current clamp value for I_dAP during a dendritic action potenti\n",
    "    p['soma_params']['tau_dAP'] = 60.       # time window over which the dendritic current clamp is active\n",
    "    p['soma_params']['theta_dAP'] = 59.        # current threshold for a dendritic action potential\n",
    "    p['fixed_somatic_delay'] = 2          # this is an approximate time of how long it takes the soma to fire\n",
    "                                          # upon receiving an external stimulus \n",
    "    \n",
    "    p['soma_params']['I_dend_incr'] = 2.71 / (p['soma_params']['tau_syn2'])\n",
    "\n",
    "    # synaptic parameters\n",
    "    p['J_EX_psp'] = 1.1 * p['soma_params']['V_th']     # somatic PSP as a response to an external input\n",
    "    p['convergence'] = 5\n",
    "    p['pattern_size'] = 20       # sparse set of active neurons per subpopulation\n",
    "    \n",
    "    # parameters for ee synapses (stdsp)\n",
    "    p['syn_dict_ee'] = {}\n",
    "    p['permanence_min'] = 0.\n",
    "    p['permanence_max'] = 8.\n",
    "    p['calibration'] = 0.\n",
    "    p['syn_dict_ee']['weight'] = 0.01                    # synaptic weight\n",
    "    p['syn_dict_ee']['synapse_model'] = synapse_model_name  # synapse model\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['permanence_threshold'] = 10.                    # synapse maturity threshold\n",
    "    else:\n",
    "        p['syn_dict_ee']['th_perm'] = 10.                    # synapse maturity threshold\n",
    "\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['tau_pre_trace'] = 20.                   # plasticity time constant (potentiation)\n",
    "    else:\n",
    "        p['syn_dict_ee']['tau_plus'] = 20.                   # plasticity time constant (potentiation)\n",
    "    \n",
    "    p['syn_dict_ee']['delay'] = 2.                       # dendritic delay \n",
    "    p['syn_dict_ee']['receptor_type'] = 2                # receptor corresponding to the dendritic input\n",
    "    p['syn_dict_ee']['lambda_plus'] = 0.08                     # potentiation rate\n",
    "    p['syn_dict_ee']['zt'] = 1.                          # target dAP trace [pA]\n",
    "    p['syn_dict_ee']['lambda_h'] = 0.014                        # homeostasis rate\n",
    "    p['syn_dict_ee']['Wmax'] = 1.1 * p['soma_params']['theta_dAP'] / p['convergence']   # Maximum allowed weight\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['permanence_max'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['permanence_min'] = 1.                        # Minimum allowed permanence\n",
    "    else:\n",
    "        p['syn_dict_ee']['Pmax'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['Pmin'] = 1.                        # Minimum allowed permanence\n",
    "    p['syn_dict_ee']['lambda_minus'] = 0.0015\n",
    "\n",
    "    # parameters of EX synapses (external to soma of E neurons)\n",
    "    p['conn_dict_ex'] = {}\n",
    "    p['syn_dict_ex'] = {}\n",
    "    p['syn_dict_ex']['receptor_type'] = 1                    # receptor corresponding to external input\n",
    "    p['syn_dict_ex']['delay'] = DELAY                        # dendritic delay\n",
    "    p['conn_dict_ex']['rule'] = 'all_to_all'                 # connection rule\n",
    "    \n",
    "    ## stimulus parameters\n",
    "    p['DeltaT'] = 40.                               # inter-stimulus interval\n",
    "\n",
    "    p['seed'] = 1          # rng seed\n",
    "    \n",
    "    return p\n",
    "\n",
    "params = create_stdsp_dependence_on_third_factor_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_foobar(params):\n",
    "    \n",
    "    nest.ResetKernel()\n",
    "    nest.Install(module_name)\n",
    "    nest.set_verbosity(\"M_ALL\")\n",
    "    nest.SetKernelStatus({\n",
    "        'resolution': params['dt'],\n",
    "        'print_time': params['print_simulation_progress'],\n",
    "        'local_num_threads': n_threads,\n",
    "        'rng_seed': params['seed']\n",
    "    })\n",
    "    \n",
    "    neuron_1 = nest.Create(params['soma_model'], params=params['soma_params'])\n",
    "    neuron_2 = nest.Create(params['soma_model'], params=params['soma_params'])\n",
    "    \n",
    "    # connect two neurons\n",
    "    nest.Connect(neuron_1, neuron_2, syn_spec=params['syn_dict_ee'])\n",
    "    \n",
    "    # creation of spike generator\n",
    "    time_neuron_1 = 10.\n",
    "    time_neuron_2 = time_neuron_1 + params['DeltaT']\n",
    "    \n",
    "    training_steps = 120\n",
    "    between_exc = 5*params['DeltaT']\n",
    "    \n",
    "    times_neuron_1 = [time_neuron_1+i*between_exc for i in range(training_steps)]\n",
    "    times_neuron_2 = [time_neuron_2+i*between_exc for i in range(training_steps)]#[:10]\n",
    "    \n",
    "    # create the spike generators \n",
    "    # disable spike generator for the interval 'dis', to see the affect of stpd\n",
    "    dis = 20\n",
    "    spike_generator_1 = nest.Create('spike_generator', params={'spike_times': times_neuron_1})\n",
    "    spike_generator_2 = nest.Create('spike_generator', params={'spike_times': times_neuron_2})\n",
    "    \n",
    "    # connect the spike generator \n",
    "    \n",
    "    params['R_m_soma'] = params['soma_params']['tau_m'] / params['soma_params']['C_m']\n",
    "    params['syn_dict_ex']['weight'] = psp_max_2_psc_max(params['J_EX_psp'], \n",
    "                                                               params['soma_params']['tau_m'], \n",
    "                                                               params['soma_params']['tau_syn1'], \n",
    "                                                               params['R_m_soma'])\n",
    "    \n",
    "    syn_dict_ff = {'receptor_type': 1, 'weight': params['syn_dict_ex']['weight'], 'delay': params['syn_dict_ex']['delay']}\n",
    "    nest.Connect(spike_generator_1, neuron_1, syn_spec=syn_dict_ff)\n",
    "    nest.Connect(spike_generator_2, neuron_2, syn_spec=syn_dict_ff)\n",
    "    \n",
    "    # record voltage neuron 1, neuron 2\n",
    "    dap_mm_1 = nest.Create('multimeter', {\"record_from\": [\"dAP_trace\"]})\n",
    "    nest.Connect(dap_mm_1, neuron_1)\n",
    "    \n",
    "    dap_mm_2 = nest.Create('multimeter', {\"record_from\": [\"dAP_trace\"]})\n",
    "    nest.Connect(dap_mm_2, neuron_2)\n",
    "    \n",
    "    vm_1 = nest.Create('voltmeter')\n",
    "    vm_2 = nest.Create('voltmeter')\n",
    "    nest.Connect(vm_1, neuron_1)\n",
    "    nest.Connect(vm_2, neuron_2)\n",
    "    \n",
    "    \n",
    "    sd_1 = nest.Create('spike_recorder')\n",
    "    nest.Connect(neuron_1, sd_1)\n",
    "    \n",
    "    sd_2 = nest.Create('spike_recorder')\n",
    "    nest.Connect(neuron_2, sd_2)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    synColl = nest.GetConnections(synapse_model=synapse_model_name)\n",
    "    assert len(synColl) == 1\n",
    "    \n",
    "    print('\\n simulate')\n",
    "    zs = [0.,1.,2.]\n",
    "    weights_cs = []\n",
    "    permanences_cs = []\n",
    "    \n",
    "    for z in zs:\n",
    "    \n",
    "        weights = []\n",
    "        permanences = []\n",
    "        last_sim_time = 0\n",
    "        \n",
    "        spike_generator_1.origin = nest.GetKernelStatus('biological_time')\n",
    "        spike_generator_2.origin = nest.GetKernelStatus('biological_time')\n",
    "        \n",
    "        # connect two neurons\n",
    "        synColl.set({'permanence': 1.}) \n",
    "    \n",
    "        for i in range(training_steps):\n",
    "    \n",
    "            # change toward using the weight recorder, example:\n",
    "            #wr = nest.Create('weight_recorder')\n",
    "            #nest.CopyModel('stdp_synapse', 'stdp_synapse_rec', {'weight_recorder': wr})\n",
    "    \n",
    "            nest.SetStatus(neuron_1, {'dAP_trace':z})\n",
    "            nest.SetStatus(neuron_2, {'dAP_trace':z})\n",
    "    \n",
    "            # simulate the network\n",
    "            sim_time = times_neuron_1[i] - last_sim_time \n",
    "            nest.Simulate(sim_time)\n",
    "            last_sim_time = times_neuron_1[i]\n",
    "    \n",
    "            w_after = synColl.weight\n",
    "            p_after = synColl.permanence\n",
    "            weights.append(w_after)\n",
    "            permanences.append(p_after)\n",
    "    \n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(24,6))\n",
    "        ax.plot(nest.GetStatus(vm_1)[0]['events'][\"times\"], nest.GetStatus(vm_1)[0]['events'][\"V_m\"], label=\"vm1\")\n",
    "        max_V_m = np.amax(nest.GetStatus(vm_1)[0]['events'][\"V_m\"])\n",
    "        ax.scatter(nest.GetStatus(sd_1)[0]['events']['times'], max_V_m * np.ones_like(nest.GetStatus(sd_1)[0]['events']['times']))\n",
    "        ax.plot(nest.GetStatus(vm_2)[0]['events'][\"times\"], nest.GetStatus(vm_2)[0]['events'][\"V_m\"], label=\"vm2\")\n",
    "        ax.scatter(nest.GetStatus(sd_2)[0]['events']['times'], max_V_m * np.ones_like(nest.GetStatus(sd_2)[0]['events']['times']))\n",
    "        ax.legend()\n",
    "        ax_ = ax.twinx()\n",
    "        ax_.plot(nest.GetStatus(dap_mm_1)[0]['events'][\"times\"], nest.GetStatus(dap_mm_1)[0]['events'][\"dAP_trace\"], label=\"dAP\")\n",
    "        ax_.plot(nest.GetStatus(dap_mm_2)[0]['events'][\"times\"], nest.GetStatus(dap_mm_2)[0]['events'][\"dAP_trace\"], label=\"dAP\")\n",
    "        \n",
    "        fig.savefig(\"/tmp/foo\" + str(z) + \".png\")\n",
    "            \n",
    "        weights_cs.append(weights)\n",
    "        permanences_cs.append(permanences)\n",
    "    \n",
    "    # store postprocessed\n",
    "    params['zs'] = zs\n",
    "\n",
    "    data[\"weights_cs\"] = weights_cs\n",
    "    data[\"permanences_cs\"] = permanences_cs\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = simulate_foobar(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_foobar(data, params):\n",
    "    \n",
    "    # plot recorded data\n",
    "    # ------------------\n",
    "    \n",
    "    # plot settings \n",
    "    fig_size = (5.2, 2.)\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['legend.fontsize'] = 6\n",
    "    plt.rcParams['figure.figsize'] = fig_size\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['savefig.dpi'] = 300\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "\n",
    "    ms = 0.5\n",
    "    alpha = 0.5\n",
    "    lw_hline = 1.\n",
    "    \n",
    "    #################\n",
    "    # visualize data\n",
    "    # ---------------\n",
    "    gs = mpl.gridspec.GridSpec(1, 3, right=0.92, left=0.09, bottom=0.2, top=0.89, wspace=0.2, hspace=0.2)\n",
    "    \n",
    "    # data for Ic=0\n",
    "    # -------------\n",
    "    ax1 = plt.subplot(gs[0,0])\n",
    "    \n",
    "    training_steps = len(data[\"weights_cs\"][0])\n",
    "    num_pulses = np.arange(training_steps)\n",
    "    lns1 = ax1.plot(num_pulses, data[\"weights_cs\"][0], '-o', ms=ms, color='black', label=r'$J$')\n",
    "    \n",
    "    #plt.ylabel('weight ($\\mu$S)')\n",
    "    ax1.set_xlim(0, training_steps)\n",
    "    ax1.set_ylim(-1, params[\"syn_dict_ee\"]['Wmax']+10)\n",
    "    #ax1.set_title(r'dAP rate $\\nu_\\mathsf{d}$=%0.1f' % zs[0])\n",
    "    ax1.set_title(r'$z$=%0.1f' % params['zs'][0])\n",
    "    ax1.set_ylabel(r'weight $J$ (pA)')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    lns2 = ax2.plot(num_pulses, data[\"permanences_cs\"][0], '-o', ms=ms, color='grey', alpha=alpha, label=r'$P$')\n",
    "    if 'permanence_threshold' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_threshold'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "    if 'th_perm' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['th_perm'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "\n",
    "    if \"permanence_max\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_max'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')\n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['permanence_max']+2)\n",
    "\n",
    "    if \"Pmax\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['Pmax'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')    \n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['Pmax']+2)\n",
    "\n",
    "    \n",
    "    ax2.tick_params(axis='y', labelcolor='grey')\n",
    "    #ax2.set_yticklabels([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.spines['right'].set_color('grey')\n",
    "    \n",
    "    # add legends\n",
    "    lns = [lns1[0],lns2[0]]\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc='lower right')\n",
    "    \n",
    "    # data for Ic=1\n",
    "    # -------------\n",
    "    ax1 = plt.subplot(gs[0,1])\n",
    "    \n",
    "    ax1.plot(num_pulses, data[\"weights_cs\"][1], '-o', ms=ms, color='black', label='weight')\n",
    "    \n",
    "    ax1.set_ylim(-1, params[\"syn_dict_ee\"]['Wmax']+10)\n",
    "    ax1.set_xlim(0, training_steps)\n",
    "    #ax1.set_title(r'dAP rate $\\nu_\\mathsf{d}$=%0.1f' % params['zs'][1])\n",
    "    ax1.set_title(r'$z$=%0.1f' % params['zs'][1])\n",
    "    ax1.set_xlabel('number of presynaptic-postsynaptic spike pairings')\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(num_pulses, data[\"permanences_cs\"][1], '-o', ms=ms, color='grey', alpha=alpha, label='permanence')\n",
    "    if 'permanence_threshold' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_threshold'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "    if 'th_perm' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['th_perm'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "\n",
    "    if \"permanence_max\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_max'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')\n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['permanence_max']+2)\n",
    "\n",
    "    if \"Pmax\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['Pmax'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')    \n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['Pmax']+2)\n",
    "    \n",
    "    \n",
    "    ax2.tick_params(axis='y', labelcolor='grey')\n",
    "    ax2.set_yticks([])\n",
    "    ax2.spines['right'].set_color('grey')\n",
    "    \n",
    "    # data for Ic=2\n",
    "    # -------------\n",
    "    ax1 = plt.subplot(gs[0,2])\n",
    "    \n",
    "    ax1.plot(num_pulses, data[\"weights_cs\"][2], '-o', ms=ms, color='black', label='weight')\n",
    "    \n",
    "    ax1.set_ylim(-1, params[\"syn_dict_ee\"]['Wmax']+10)\n",
    "    ax1.set_xlim(0, training_steps)\n",
    "    #ax1.set_title(r'dAP rate $\\nu_\\mathsf{d}$=%0.1f' % params['zs'][2])\n",
    "    ax1.set_title(r'$z$=%0.1f' % params['zs'][2])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(num_pulses, data[\"permanences_cs\"][2], '-o', ms=ms, color='grey', alpha=alpha, label=r'$P$')\n",
    "    if 'permanence_threshold' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_threshold'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "    if 'th_perm' in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['th_perm'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dotted')\n",
    "    if \"permanence_max\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['permanence_max'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')\n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['permanence_max']+2)\n",
    "\n",
    "    if \"Pmax\" in params['syn_dict_ee'].keys():\n",
    "        plt.hlines(params['syn_dict_ee']['Pmax'], 0, training_steps, lw=lw_hline, color='grey', linestyles='dashed')    \n",
    "        ax2.set_ylim(-1, params[\"syn_dict_ee\"]['Pmax']+2)\n",
    "\n",
    "    ax2.tick_params(axis='y', labelcolor='grey')\n",
    "    ax2.set_ylabel(r\"permanence $P$\", color=\"grey\")\n",
    "    #ax2.spines['right'].set_color('grey')\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    path = '.'\n",
    "    fname = 'plasticity_dynamics'\n",
    "    #print(\"save %s/%s.pdf\" % (path, fname))\n",
    "    #plt.savefig(\"/tmp/%s.pdf\" % fname)\n",
    "    plt.savefig(\"/tmp/%s.png\" % fname)\n",
    "\n",
    "plot_foobar(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Network sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_active_dendrite_parameters():\n",
    "    DELAY = 0.1\n",
    "    \n",
    "    p = para.ParameterSpace({})\n",
    "    \n",
    "    p['dt'] = 0.1                                  # simulation time resolution (ms)\n",
    "    p['print_simulation_progress'] = True         # print the time progress.\n",
    "    \n",
    "    # neuron parameters of the excitatory neurons\n",
    "    p['soma_model'] = neuron_model_name\n",
    "    p['soma_params'] = {}\n",
    "    p['soma_params']['C_m'] = 250.        # membrane capacitance (pF)\n",
    "    p['soma_params']['E_L'] = 0.          # resting membrane potential (mV)\n",
    "    # p['soma_params']['I_e'] = 0.        # external DC currents (pA)\n",
    "    p['soma_params']['V_m'] = 0.          # initial potential (mV)\n",
    "    p['soma_params']['V_reset'] = 0.      # reset potential (mV)\n",
    "    p['soma_params']['V_th'] = 20.        # spike threshold (mV)\n",
    "    p['soma_params']['t_ref'] = 10.       # refractory period\n",
    "    p['soma_params']['tau_m'] = 10.       # membrane time constant (ms)\n",
    "    p['soma_params']['tau_syn1'] = 2.     # synaptic time constant: external input (receptor 1)\n",
    "    p['soma_params']['tau_syn2'] = 5.     # synaptic time constant: dendrtic input (receptor 2)\n",
    "    p['soma_params']['tau_syn3'] = 1.     # synaptic time constant: inhibitory input (receptor 3)\n",
    "    # dendritic action potential\n",
    "    p['soma_params']['I_p'] = 200. # current clamp value for I_dAP during a dendritic action potenti\n",
    "    p['soma_params']['tau_dAP'] = 60.       # time window over which the dendritic current clamp is active\n",
    "    p['soma_params']['theta_dAP'] = 59.        # current threshold for a dendritic action potential\n",
    "    \n",
    "    p['soma_params']['I_dend_incr'] = 2.71 / (p['soma_params']['tau_syn2'])\n",
    "    \n",
    "    \n",
    "    p['fixed_somatic_delay'] = 2          # this is an approximate time of how long it takes the soma to fire\n",
    "                                          # upon receiving an external stimulus \n",
    "    \n",
    "        \n",
    "    \n",
    "    # neuron parameters for the inhibitory neuron\n",
    "    p['inhibit_model'] = 'iaf_psc_exp'\n",
    "    p['inhibit_params'] = {}\n",
    "    p['inhibit_params']['C_m'] = 250.         # membrane capacitance (pF)\n",
    "    p['inhibit_params']['E_L'] = 0.           # resting membrane potential (mV)\n",
    "    p['inhibit_params']['I_e'] = 0.           # external DC currents (pA)\n",
    "    p['inhibit_params']['V_m'] = 0.           # initial potential (mV)\n",
    "    p['inhibit_params']['V_reset'] = 0.       # reset potential (mV)\n",
    "    p['inhibit_params']['V_th'] = 15.         # spike threshold (mV)\n",
    "    p['inhibit_params']['t_ref'] = 2.0        # refractory period\n",
    "    p['inhibit_params']['tau_m'] = 5.         # membrane time constant (ms)\n",
    "    p['inhibit_params']['tau_syn_ex'] = .5    # synaptic time constant of an excitatory input (ms) \n",
    "    p['inhibit_params']['tau_syn_in'] = 1.65  # synaptic time constant of an inhibitory input (ms)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    # synaptic parameters\n",
    "    p['J_EX_psp'] = 1.1 * p['soma_params']['V_th']     # somatic PSP as a response to an external input\n",
    "    p['J_IE_psp'] = 1.2 * p['inhibit_params']['V_th']  # inhibitory PSP as a response to an input from E neuron\n",
    "    p['J_EI_psp'] = -2 * p['soma_params']['V_th']      # somatic PSP as a response to an inhibitory input\n",
    "    p['convergence'] = 5\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # parameters for setting up the network  \n",
    "    p['M'] = 6                   # number of subpopulations\n",
    "    p['n_E'] = 150               # number of excitatory neurons per subpopulation\n",
    "    p['n_I'] = 1                 # number of inhibitory neurons per subpopulation\n",
    "    p['L'] = 1                   # number of subpopulations that represents one sequence element\n",
    "    p['pattern_size'] = 20       # sparse set of active neurons per subpopulation\n",
    "    \n",
    "    # connection details\n",
    "    p['rule'] = 'fixed_indegree'                          \n",
    "    p['connection_prob'] = 0.2\n",
    "    \n",
    "    # synaptic parameters\n",
    "    p['J_EX_psp'] = 1.1 * p['soma_params']['V_th']     # somatic PSP as a response to an external input\n",
    "    p['J_EI_psp'] = -2 * p['soma_params']['V_th']      # somatic PSP as a response to an inhibitory input\n",
    "    p['convergence'] = 5\n",
    "    \n",
    "    # parameters for ee synapses (stdsp)\n",
    "    p['syn_dict_ee'] = {}\n",
    "    p['permanence_min'] = 0.\n",
    "    p['permanence_max'] = 8.\n",
    "\n",
    "\n",
    "    \n",
    "    p['calibration'] = 0.\n",
    "    p['syn_dict_ee']['weight'] = 0.01                    # synaptic weight\n",
    "    p['syn_dict_ee']['synapse_model'] = synapse_model_name  # synapse model\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['permanence_threshold'] = 10.                    # synapse maturity threshold\n",
    "        p['syn_dict_ee']['tau_pre_trace'] = 20.                   # plasticity time constant (potentiation)\n",
    "    else:\n",
    "        p['syn_dict_ee']['th_perm'] = 10.                    # synapse maturity threshold\n",
    "        p['syn_dict_ee']['tau_plus'] = 20.                   # plasticity time constant (potentiation)\n",
    "    p['syn_dict_ee']['delay'] = 2.                       # dendritic delay \n",
    "    p['syn_dict_ee']['receptor_type'] = 2                # receptor corresponding to the dendritic input\n",
    "    p['syn_dict_ee']['lambda_plus'] = 0.08               # potentiation rate\n",
    "    p['syn_dict_ee']['zt'] = 1.                          # target dAP trace\n",
    "    p['syn_dict_ee']['lambda_h'] = 0.014                 # homeostasis rate\n",
    "    p['syn_dict_ee']['Wmax'] = 1.1 * p['soma_params']['theta_dAP'] / p['convergence']   # Maximum allowed weight\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['permanence_max'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['permanence_min'] = 1.                        # Minimum allowed permanence\n",
    "    else:\n",
    "        p['syn_dict_ee']['Pmax'] = 20.                       # Maximum allowed permanence\n",
    "        p['syn_dict_ee']['Pmin'] = 1.                        # Minimum allowed permanence\n",
    "    p['syn_dict_ee']['lambda_minus'] = 0.0015            # depression rate\n",
    "    if \"synapse_nestml\" in synapse_model_name:\n",
    "        p['syn_dict_ee']['dt_min'] = 4.                     # minimum time lag of the STDP window\n",
    "    else:\n",
    "        p['syn_dict_ee']['dt_min'] = -4.                     # minimum time lag of the STDP window\n",
    "    p['inh_factor'] = 7.\n",
    "    \n",
    "    # parameters of EX synapses (external to soma of E neurons)\n",
    "    p['conn_dict_ex'] = {}\n",
    "    p['syn_dict_ex'] = {}\n",
    "    p['syn_dict_ex']['receptor_type'] = 1                    # receptor corresponding to external input\n",
    "    p['syn_dict_ex']['delay'] = DELAY                        # dendritic delay\n",
    "    p['conn_dict_ex']['rule'] = 'all_to_all'                 # connection rule\n",
    "    \n",
    "    # parameters of EdX synapses (external to dendrite of E neurons) \n",
    "    p['conn_dict_edx'] = {}\n",
    "    p['syn_dict_edx'] = {}\n",
    "    p['syn_dict_edx']['receptor_type'] = 2                    # receptor corresponding to the dendritic input\n",
    "    p['syn_dict_edx']['delay'] = DELAY                        # dendritic delay\n",
    "    p['syn_dict_edx']['weight'] = 1.4 * p['soma_params']['theta_dAP']\n",
    "    p['conn_dict_edx']['rule'] = 'fixed_outdegree'            # connection rule\n",
    "    p['conn_dict_edx']['outdegree'] = p['pattern_size'] + 1   # outdegree\n",
    "    \n",
    "    # parameters for IE synapses \n",
    "    p['syn_dict_ie'] = {}\n",
    "    p['conn_dict_ie'] = {}\n",
    "    p['syn_dict_ie']['synapse_model'] = 'static_synapse'     # synapse model\n",
    "    p['syn_dict_ie']['delay'] = DELAY                        # dendritic delay\n",
    "    p['conn_dict_ie']['rule'] = 'fixed_indegree'             # connection rule\n",
    "    p['conn_dict_ie']['indegree'] = 5                        # indegree \n",
    "    \n",
    "    # parameters for EI synapses\n",
    "    p['syn_dict_ei'] = {}\n",
    "    p['conn_dict_ei'] = {}\n",
    "    p['syn_dict_ei']['synapse_model'] = 'static_synapse'     # synapse model\n",
    "    p['syn_dict_ei']['delay'] = DELAY                        # dendritic delay\n",
    "    p['syn_dict_ei']['receptor_type'] = 3                    # receptor corresponding to the inhibitory input  \n",
    "    p['conn_dict_ei']['rule'] = 'fixed_indegree'             # connection rule\n",
    "    p['conn_dict_ei']['indegree'] = 20                       # indegree\n",
    "    \n",
    "    # stimulus parameters\n",
    "    p['DeltaT'] = 40.                     # inter-stimulus interval\n",
    "    p['excitation_start'] = 30.           # time at which the external stimulation begins\n",
    "    p['time_dend_to_somatic'] = 20.       # time between the dAP activation and the somatic activation (only used if sparse_first_char is True)   \n",
    "    p['DeltaT_cue'] = 80.                 # inter-cue interval during replay\n",
    "    \n",
    "    # simulation parameters \n",
    "    p['dt'] = 0.1                                  # simulation time resolution (ms)\n",
    "    p['overwrite_files'] = True                    # if True, data will be overwritten,\n",
    "                                                   # if False, a NESTError is raised if the files already exist\n",
    "    p['seed'] = para.ParameterRange([1,2,3,4,5])   # seed for NEST\n",
    "    p['print_simulation_progress'] = True         # print the time progress.\n",
    "    p['pad_time'] = 5.\n",
    "    p['idend_recording_interval'] = 10 * p['dt']   # dendritic current recording resolution\n",
    "    p['idend_record_time'] = 8.                    # time interval after the external stimulation at which the dendritic current is recorded\n",
    "    p['evaluate_performance'] = True               # if turned on, we monitor the dendritic current at a certain time steps\n",
    "                                                   # during the simulation. This then is used for the prediction performance assessment\n",
    "    p['evaluate_replay'] = False                     \n",
    "    p['record_idend_last_episode'] = True          # used for debugging, if turned on we record the dendritic current of all neurons\n",
    "                                                   # this can consume too much memory\n",
    "    p['store_connections'] = False              \n",
    "    p['load_connections'] = False\n",
    "    p['sparse_first_char'] = False                 # if turned on, the dAP of a subset of neurons in the subpopulation representing \n",
    "                                                   # first sequence elements is activated externally \n",
    "    p['active_weight_recorder'] = False            # if turned on, the weights are recorded every presynaptic spike\n",
    "    \n",
    "    # task parameters\n",
    "    p['task'] = {}\n",
    "    p['task']['task_name'] = 'hard_coded'          # name of the task\n",
    "    p['task']['task_type'] = 1                     # this chooses between three hard coded sequence sets (see ./utils.py)\n",
    "    p['task']['vocab_size'] = 6                   # vocabulary size\n",
    "    p['task']['seed'] = 111                        # seed number\n",
    "    p['task']['store_training_data'] = True        # if turned on, the sequence set is stored in directory defined in dict data_path\n",
    "    if p['task']['task_name'] != 'hard_coded':\n",
    "        p['task']['num_sequences'] = 2             # number of sequences per sequence set\n",
    "        p['task']['num_sub_seq'] = 2               # if task_name == 'high_order', \n",
    "                                                   # it sets the number of sequences with same shared subsequence\n",
    "        p['task']['length_sequence'] = 6           # number of elements per sequence\n",
    "        p['task']['replace'] = False               # random choice of characters with replacement\n",
    "    \n",
    "    # setup the training loop  \n",
    "    p['learning_episodes'] = 42 #XXX: was 85                     # total number of training episodes ('repetitions of the sequence sets')\n",
    "    p['episodes_to_testing'] = 1                   # number of episodes after which we measure the prediction perfomance\n",
    "\n",
    "    if \"synapse_nestml\" not in synapse_model_name:\n",
    "        p['mu_plus']= 0.0 \n",
    "        p['mu_minus']= 0.0\n",
    "\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "params = create_active_dendrite_parameters()\n",
    "\n",
    "run_psc_test(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiments/sequence_learning_and_prediction/local_simulation.py\n",
    "\n",
    "def generate_sequences(params, fname):\n",
    "    \"\"\"Generate sequence of elements using three methods:\n",
    "    1. randomly drawn elements from a vocabulary\n",
    "    2. sequences with transition matrix\n",
    "    3. higher order sequences: sequences with shared subsequences\n",
    "    4. hard coded sequences\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        dictionary contains task parameters\n",
    "    fname       : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sequences: list\n",
    "    test_sequences: list\n",
    "    vocabulary: list\n",
    "    \"\"\"\n",
    "\n",
    "    task_name = params['task_name']\n",
    "    task_type = params['task_type']\n",
    " \n",
    "    # set of characters used to build the sequences\n",
    "    vocabulary = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                  'U', 'V', 'W', 'X', 'Y', 'Z'][:params['vocab_size']]\n",
    "    sequences = []\n",
    "\n",
    "    # create high order sequences, characters are drawn without replacement\n",
    "    if task_name == \"high_order\":\n",
    "\n",
    "        if (params['num_sequences'] % params['num_sub_seq'] != 0):\n",
    "            raise ZeroDivisionError(\n",
    "                'for high order sequences number of sequences needs (\"num_sequences\") to be divisible by num_sub_seq')\n",
    "\n",
    "        num_sequences_high_order = int(params['num_sequences'] / params['num_sub_seq'])\n",
    "        for i in range(num_sequences_high_order):\n",
    "            characters_sub_seq = copy.copy(vocabulary)\n",
    "            sub_seq = random.sample(characters_sub_seq, params[\"length_sequence\"] - 2)\n",
    "            for char in sub_seq:\n",
    "                characters_sub_seq.remove(char)\n",
    "\n",
    "            for j in range(params['num_sub_seq']):\n",
    "                # remove the characters that were chosen for the end and the start of the sequence\n",
    "                # this is to avoid sequences with adjacent letters of the same kind\n",
    "                # we will add this feature to the code asap \n",
    "                end_char = random.sample(characters_sub_seq, 1)\n",
    "                characters_sub_seq.remove(end_char[0])\n",
    "\n",
    "                start_char = random.sample(characters_sub_seq, 1)\n",
    "                characters_sub_seq.remove(start_char[0])\n",
    "\n",
    "                sequence = start_char + sub_seq + end_char\n",
    "                sequences.append(sequence)\n",
    "\n",
    "                # randomly shuffled characters\n",
    "    elif task_name == \"random\":\n",
    "        sequences = [random.sample(vocabulary, length_seq) for _ in range(params['num_sequences'])]\n",
    "\n",
    "    # create sequences using matrix transition \n",
    "    elif task_name == \"structure\":\n",
    "        matrix_transition = defaultdict(list)\n",
    "        for char in vocabulary:\n",
    "            x = np.random.choice(2, len(vocabulary), p=[0.2, 0.8])\n",
    "            matrix_transition[char] = x / sum(x)\n",
    "\n",
    "        for _ in range(params['num_sequences']):\n",
    "            sequence = random.sample(vocabulary, 1)\n",
    "            last_char = sequence[-1]\n",
    "            for _ in range(length_seq - 1):\n",
    "                sequence += np.random.choice(vocabulary, 1, p=matrix_transition[last_char])[0]\n",
    "                last_char = sequence[-1]\n",
    "\n",
    "            sequences += [sequence]\n",
    "    else:\n",
    "\n",
    "        # hard coded sequences \n",
    "        if task_type == 1:\n",
    "            sequences = [['A', 'D', 'B', 'E'], ['F', 'D', 'B', 'C']]\n",
    "        elif task_type == 2:\n",
    "            sequences = [['E', 'N', 'D', 'I', 'J'], ['L', 'N', 'D', 'I', 'K'], ['G', 'J', 'M', 'C', 'N'], \n",
    "                         ['F', 'J', 'M', 'C', 'I'], ['B', 'C', 'K', 'H', 'I'], ['A', 'C', 'K', 'H', 'F']]\n",
    "        elif task_type == 3:\n",
    "            sequences = [['E', 'N', 'D', 'I', 'J'], ['L', 'N', 'D', 'I', 'K'], ['G', 'J', 'M', 'E', 'N'], \n",
    "                         ['F', 'J', 'M', 'E', 'I'], ['B', 'C', 'K', 'B', 'I'], ['A', 'C', 'K', 'B', 'F']]\n",
    "        else:\n",
    "            sequences = [['A', 'D', 'B', 'G', 'H', 'E'], ['F', 'D', 'B', 'G', 'H', 'C']]\n",
    "\n",
    "    # test sequences used to measure the accuracy \n",
    "    test_sequences = sequences\n",
    "\n",
    "    fname = 'training_data'\n",
    "    fname_voc = 'vocabulary'\n",
    "    print(\"\\nSave training data to %s\" % (fname))\n",
    "    np.save('%s' % os.path.join( fname), sequences)\n",
    "    np.save('%s' % os.path.join( fname_voc), vocabulary)\n",
    "\n",
    "    return sequences, test_sequences, vocabulary\n",
    "\n",
    "\n",
    "def generate_reference_data(params):\n",
    "\n",
    "    #############################################################\n",
    "    # get network and training parameters \n",
    "    # ===========================================================\n",
    "    p = copy.deepcopy(params)\n",
    "    PS = copy.deepcopy(p)\n",
    "\n",
    "    # parameter-set id from command line (submission script)\n",
    "    PL = shtm.helper.parameter_set_list(PS) \n",
    "    params = PL[0]\n",
    "\n",
    "    # start time \n",
    "    time_start = time.time()\n",
    "\n",
    "    # ###############################################################\n",
    "    # specify sequences\n",
    "    # ===============================================================\n",
    "    sequences, _, vocabulary = generate_sequences(params['task'], PL[0]['label'])\n",
    "\n",
    "    # ###############################################################\n",
    "    # create network\n",
    "    # ===============================================================\n",
    "    model_instance = Model(params, sequences, vocabulary)\n",
    "    time_model = time.time()\n",
    "\n",
    "    model_instance.create()\n",
    "    time_create = time.time()\n",
    "\n",
    "    # ###############################################################\n",
    "    # connect the netwok\n",
    "    # ===============================================================\n",
    "    print(\"connect().....\")\n",
    "\n",
    "    model_instance.connect()\n",
    "    print(\"connect()ed\")\n",
    "    time_connect = time.time()\n",
    "    \n",
    "    # store connections before learning\n",
    "    print(\"Store connections.....\")\n",
    "    if params['store_connections']:\n",
    "        model_instance.save_connections(fname='ee_connections_before')\n",
    "\n",
    "    # ###############################################################\n",
    "    # simulate the network\n",
    "    # ===============================================================\n",
    "    print(\"Simulating.....\")\n",
    "\n",
    "    model_instance.simulate()\n",
    "    time_simulate = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Store connections.....\")\n",
    "    \n",
    "    # store connections after learning\n",
    "    if True:#params['store_connections']:\n",
    "        model_instance.save_connections(fname='ee_connections')\n",
    "\n",
    "    print(\n",
    "        '\\nTimes of Rank {}:\\n'.format(\n",
    "            nest.Rank()) +\n",
    "        '  Total time:          {:.3f} s\\n'.format(\n",
    "            time_simulate -\n",
    "            time_start) +\n",
    "        '  Time to initialize:  {:.3f} s\\n'.format(\n",
    "            time_model -\n",
    "            time_start) +\n",
    "        '  Time to create:      {:.3f} s\\n'.format(\n",
    "            time_create -\n",
    "            time_model) +\n",
    "        '  Time to connect:     {:.3f} s\\n'.format(\n",
    "            time_connect -\n",
    "            time_create) +\n",
    "        '  Time to simulate:    {:.3f} s\\n'.format(\n",
    "            time_simulate -\n",
    "            time_connect))\n",
    "\n",
    "    #\n",
    "    # PLOTTING\n",
    "    #\n",
    "\n",
    "    nest.raster_plot.from_device(model_instance.spike_recorder_soma)\n",
    "    fname_snip = str(time.time())\n",
    "    plt.savefig(\"/tmp/nestml_raster_\"+fname_snip + \".png\")\n",
    "\n",
    "    for gid in [1, 100, 200]:\n",
    "\n",
    "        \n",
    "        events = model_instance.spike_recorder_soma_.get()[\"events\"]\n",
    "        times = events[\"times\"]\n",
    "        senders = events[\"senders\"]\n",
    "        idx = np.where(senders == gid)[0]\n",
    "        spike_times = events[\"times\"][idx]\n",
    "\n",
    "        events = model_instance.multimeter_vm_eval_.get()[\"events\"]\n",
    "        times = events[\"times\"]\n",
    "        senders = events[\"senders\"]\n",
    "        idx = np.where(senders == gid)[0]\n",
    "        V_m = events[\"V_m\"][idx]\n",
    "        times = times[idx]\n",
    "        assert len(times) > 100\n",
    "\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(times, V_m)\n",
    "        ax.scatter(spike_times, np.zeros_like(spike_times), marker=\"D\", alpha=.5)\n",
    "        ax.set_ylabel(\"V_m\")\n",
    "        fig.savefig(\"/tmp/nestml_V_m_\" + str(gid) + \"_\" + fname_snip + \".png\")\n",
    "    \n",
    "        events = model_instance.multimeter_idend_eval_.get()[\"events\"]\n",
    "        times = events[\"times\"]\n",
    "        senders = events[\"senders\"]\n",
    "        idx = np.where(senders == gid)[0]\n",
    "        I_dend = events[\"I_dend\"][idx]\n",
    "        times = times[idx]\n",
    "        assert len(times) > 100\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(times, I_dend)\n",
    "        ax.set_ylabel(\"I_dend\")\n",
    "        fig.savefig(\"/tmp/nestml_I_dend_\"  + str(gid) + \"_\" + fname_snip + \".png\")\n",
    "\n",
    "    events = model_instance.spike_recorder_inh_.get()[\"events\"]\n",
    "    times = events[\"times\"]\n",
    "    senders = events[\"senders\"]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i, gid in enumerate(np.unique(senders)):\n",
    "        idx = np.where(senders == gid)[0]\n",
    "        spike_times = events[\"times\"][idx]\n",
    "\n",
    "        ax.scatter(spike_times, i * np.ones_like(spike_times), marker=\"D\", alpha=.5)\n",
    "    ax.set_ylabel(\"Inhibitory neuron idx\")\n",
    "    fig.savefig(\"/tmp/nestml_inhibitory_spikes_\" + str(gid) + \"_\" + fname_snip + \".png\")\n",
    "        \n",
    "    \n",
    "    # print Ic\n",
    "    #zs = np.array([nest.GetStatus(model_instance.exc_neurons)[i]['z'] for i in range(params['M']*params['n_E'])])\n",
    "    #id_zs = np.where(zs>0.5)\n",
    "    #print(zs[id_zs])\n",
    "\n",
    "    # load spikes from reference data\n",
    "    somatic_spikes = shtm.helper.load_spike_data(model_instance.data_path, 'somatic_spikes')\n",
    "    idend_eval = shtm.helper.load_spike_data(model_instance.data_path, 'idend_eval')\n",
    "    excitation_times = shtm.helper.load_data(model_instance.data_path, 'excitation_times')\n",
    "\n",
    "    # get recoding times of dendriticAP\n",
    "    idend_recording_times = shtm.helper.load_data(model_instance.data_path,  'idend_recording_times')\n",
    "    characters_to_subpopulations = shtm.helper.load_data(model_instance.data_path,  'characters_to_subpopulations')\n",
    "\n",
    "    seq_avg_errors, seq_avg_false_positives, seq_avg_false_negatives, _ = shtm.helper.compute_prediction_performance(somatic_spikes, idend_eval, idend_recording_times, characters_to_subpopulations, model_instance.sequences, model_instance.params)\n",
    "\n",
    "    # get number of active neuron for each element in the sequence\n",
    "    number_elements_per_batch = sum([len(seq) for seq in model_instance.sequences])\n",
    "    start_time = excitation_times[-number_elements_per_batch] - 5 \n",
    "    end_time = excitation_times[-1] + 5\n",
    "\n",
    "    idx_times = np.where((np.array(excitation_times) > start_time) & (np.array(excitation_times) < end_time))  \n",
    "    excitation_times_sel = np.array(excitation_times)[idx_times]\n",
    "\n",
    "    num_active_neurons = shtm.helper.number_active_neurons_per_element(model_instance.sequences, somatic_spikes[:,1], somatic_spikes[:,0], excitation_times_sel, params['fixed_somatic_delay'])\n",
    "\n",
    "    print(\"\\n##### testing sequences with number of somatic spikes \")\n",
    "    count_false_negatives = 0\n",
    "    for i, (sequence, seq_counts) in enumerate(zip(model_instance.sequences, num_active_neurons)): \n",
    "        seq = ''\n",
    "        for j, (char, counts) in enumerate(zip(sequence, seq_counts)):\n",
    "            seq += str(char)+'('+ str(seq_counts[char])+')'.ljust(2)\n",
    "\n",
    "            if j != 0 and seq_counts[char] > 0.5*params['n_E']:\n",
    "                count_false_negatives += 1\n",
    "\n",
    "        print(\"sequence %d: %s\" % (i, seq))   \n",
    "\n",
    "    print(\"False negative counts\", count_false_negatives)   \n",
    "\n",
    "    print(\"\\n### Plasticity parameters\")\n",
    "    print(\"lambda plus: %0.4f\" % params['syn_dict_ee']['lambda_plus'])\n",
    "    print(\"lambda homeostasis: %0.4f\" % params['syn_dict_ee']['lambda_h'])\n",
    "    print(\"lambda minus: %0.4f\" % model_instance.params['syn_dict_ee']['lambda_minus']) \n",
    "    print(\"inh factor:\", params['inh_factor'])\n",
    "    print(\"excitation step %0.1fms\" % params['DeltaT']) #30-50  \n",
    "    print(\"seed number: %d\" % params['seed']) \n",
    "    print(\"number of learning episodes: %d\" % params['learning_episodes'])\n",
    "\n",
    "    return model_instance\n",
    "\n",
    "model_instance = generate_reference_data(params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: experiments/sequence_learning_and_prediction/prediction_performance_analysis.py\n",
    "\n",
    "def analyse_prediction_performance(params, model_instance):\n",
    "    PS = copy.deepcopy(params)\n",
    "    PS_sel = copy.deepcopy(PS)\n",
    "    compute_overlap = True\n",
    "    \n",
    "    PL = shtm.helper.parameter_set_list(PS_sel)\n",
    "    \n",
    "    # get training data\n",
    "    sequences = shtm.helper.load_data('.', 'training_data')\n",
    "    \n",
    "    print(\"#### sequences used for training ### \")\n",
    "    for i, sequence in enumerate(sequences): \n",
    "        seq = '' \n",
    "        for char in sequence:\n",
    "            seq += str(char).ljust(2) \n",
    "        print(\"sequence %d: %s\" % (i, seq))\n",
    "    \n",
    "    fname = 'prediction_performance'\n",
    "    for cP, p in enumerate(PL):\n",
    "    \n",
    "        data = {}\n",
    "    \n",
    "        # get data path\n",
    "        # load somatic spikes and dendritic current\n",
    "        somatic_spikes = shtm.helper.load_spike_data(model_instance.data_path, 'somatic_spikes')\n",
    "        idend_eval = shtm.helper.load_spike_data(model_instance.data_path,  'idend_eval')\n",
    "    \n",
    "        # load record and excitation times \n",
    "        print(\"Loading idend_recording_times from \" + str(os.path.join(model_instance.data_path,  'idend_recording_times')))\n",
    "        idend_recording_times = shtm.helper.load_data(model_instance.data_path,  'idend_recording_times')\n",
    "        characters_to_subpopulations = shtm.helper.load_data(model_instance.data_path,  'characters_to_subpopulations')\n",
    "        excitation_times = shtm.helper.load_data(model_instance.data_path,  'excitation_times')\n",
    "    \n",
    "        # compute prediction performance\n",
    "        errors, false_positives, false_negatives, num_active_neurons = shtm.helper.compute_prediction_performance(somatic_spikes, idend_eval, idend_recording_times, characters_to_subpopulations, sequences, p)\n",
    "    \n",
    "        if compute_overlap:\n",
    "            # sequences overlap\n",
    "            sequences_overlap = shtm.helper.measure_sequences_overlap(sequences, somatic_spikes[:,1], somatic_spikes[:,0], excitation_times, p['fixed_somatic_delay'], p['learning_episodes'])\n",
    "            data['overlap'] = sequences_overlap\n",
    "    \n",
    "        data['error'] = errors\n",
    "        data['false_positive'] = false_positives\n",
    "        data['false_negative'] = false_negatives\n",
    "        data['rel_active_neurons'] = num_active_neurons/p['n_E']\n",
    "        data['ep_num'] = p['episodes_to_testing'] * np.arange(int(p['learning_episodes']/p['episodes_to_testing'])+1)\n",
    "    \n",
    "        ep_to_sol = np.where(errors < 0.01)[0] \n",
    "        if len(ep_to_sol) == 0:\n",
    "            print(\"number of episodes to convergence\", p['learning_episodes'])\n",
    "        else:    \n",
    "            print(\"number of episodes to convergence\", data['ep_num'][ep_to_sol][0])\n",
    "    \n",
    "        # save data\n",
    "        print(\"Saving to \" + str(os.path.join(model_instance.data_path, fname)))\n",
    "        np.save(\"%s\" % os.path.join(model_instance.data_path, fname), data)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = analyse_prediction_performance(params, model_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, fname):\n",
    "    \"\"\"Load data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "    fname: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: this is temporary hack!\n",
    "    try:\n",
    "      data = np.load('%s/%s.npy' % (path, fname), allow_pickle=True).item()\n",
    "    except:\n",
    "      data = np.load('%s/%s.npy' % (path, fname), allow_pickle=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def plot_data(data, params):\n",
    "    \n",
    "    # get parameters \n",
    "    PS = copy.deepcopy(params)\n",
    "    PS_sel = copy.deepcopy(PS)\n",
    "    \n",
    "    params = PS_sel\n",
    "    num_neurons = params['M'] * params['n_E']\n",
    "    \n",
    "    # get trained sequences and vocabulary\n",
    "    sequences = shtm.helper.load_data('.', 'training_data')\n",
    "    vocabulary = shtm.helper.load_data('.', 'vocabulary')\n",
    "    \n",
    "    print('#### sequences used for training ### ')\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        seq = ''\n",
    "        for char in sequence:\n",
    "            seq += str(char).ljust(2)\n",
    "        print('sequence %d: %s' % (i, seq))\n",
    "    \n",
    "    # load spikes\n",
    "    somatic_spikes = shtm.helper.load_spike_data(model_instance.data_path, 'somatic_spikes')\n",
    "    idend = shtm.helper.load_spike_data(model_instance.data_path, 'idend_last_episode')\n",
    "    \n",
    "    # load spike recordings\n",
    "    idend_recording_times = shtm.helper.load_data(model_instance.data_path,  'idend_recording_times')\n",
    "    characters_to_subpopulations = shtm.helper.load_data(model_instance.data_path, 'characters_to_subpopulations')\n",
    "    characters_to_time_excitation = shtm.helper.load_data(model_instance.data_path, 'excitation_times_soma')\n",
    "    \n",
    "    # load excitation times\n",
    "    excitation_times = shtm.helper.load_data(model_instance.data_path, 'excitation_times')\n",
    "    \n",
    "    # get dendritic AP\n",
    "    idx = np.where((idend[:, 2] > params['soma_params']['theta_dAP']))[0]\n",
    "    dendriticAP_currents = idend[:, 2][idx]\n",
    "    dendriticAP_times = idend[:, 1][idx]\n",
    "    dendriticAP_senders = idend[:, 0][idx]\n",
    "    \n",
    "    # organize the characters for plotting purpose\n",
    "    subpopulation_indices = []\n",
    "    chars_per_subpopulation = []\n",
    "    for char in vocabulary:\n",
    "        # shift the subpopulation indices for plotting purposes \n",
    "        char_to_subpopulation_indices = characters_to_subpopulations[char]\n",
    "        subpopulation_indices.extend(char_to_subpopulation_indices)\n",
    "    \n",
    "        chars_per_subpopulation.extend(char * len(characters_to_subpopulations[char]))\n",
    "    \n",
    "    shifted_subpopulation_indices = np.array(subpopulation_indices) + 0.5\n",
    "    \n",
    "    # ####################################################\n",
    "    # plotting routing\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    # plot settings \n",
    "    fig_size = (5.2, 5.7)\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['legend.fontsize'] = 6\n",
    "    plt.rcParams['figure.figsize'] = fig_size\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['savefig.dpi'] = 300\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "    \n",
    "    panel_label_pos = (-0.14,0.5)\n",
    "    panel_labels = ['B', 'D', 'F']\n",
    "    color_soma_spike = '#DB2763'\n",
    "    color_dendrite_spike = '#00B4BE' \n",
    "    fc_bg = '#dcdcdc'\n",
    "    fraction_active = 3\n",
    "    delta_time = 5.\n",
    "    ymin = -0.1\n",
    "    ymax = 2\n",
    "    xmin = 0\n",
    "    master_file_name = 'network_activity'\n",
    "    \n",
    "    # set up the figure frame\n",
    "    fig = plt.figure()\n",
    "    gs = mpl.gridspec.GridSpec(6, 2, height_ratios=[3, 15, 3, 15, 3, 15], bottom=0.07, right=0.95, top=1., wspace=0., hspace=0.)\n",
    "    \n",
    "    # panel A (placeholder for svg figure to be inserted; see below)\n",
    "    panel_label_pos_shift = (-0.26, 0.5)\n",
    "    plt.subplot(gs[0, 0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # panel C (placeholder for svg figure to be inserted; see below)\n",
    "    plt.subplot(gs[2, 0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # panel C (placeholder for svg figure to be inserted; see below)\n",
    "    plt.subplot(gs[4, 0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for j, (learn, seq_num) in enumerate(zip([False, True, True], [0, 0, 1])):\n",
    "    \n",
    "        ###################################\n",
    "        # postprocessing of data\n",
    "        # ---------------------------------\n",
    "        if learn and seq_num == 0:\n",
    "            start_time = characters_to_time_excitation[sequences[0][0]][-1] - params['pad_time']\n",
    "            end_time = characters_to_time_excitation[sequences[0][-1]][-1] + params['pad_time']\n",
    "        elif learn and seq_num == 1:\n",
    "            start_time = characters_to_time_excitation[sequences[1][0]][-1] - params['pad_time']\n",
    "            end_time = characters_to_time_excitation[sequences[1][-1]][-1] + params['pad_time']\n",
    "        else:\n",
    "            start_time = characters_to_time_excitation[sequences[0][0]][0] - params['pad_time']\n",
    "            end_time = characters_to_time_excitation[sequences[0][-1]][0] + params['pad_time']\n",
    "    \n",
    "        # select data  corresponding to the different sequences\n",
    "        idx_somatic_spikes = np.where((somatic_spikes[:,1] > start_time) & (somatic_spikes[:,1] < end_time))\n",
    "        idx_dAP = np.where((dendriticAP_times > start_time) & (dendriticAP_times < end_time))\n",
    "    \n",
    "        # postprocess somatic spikes\n",
    "        somatic_spikes_times = somatic_spikes[:,1][idx_somatic_spikes]\n",
    "        somatic_spikes_senders = somatic_spikes[:,0][idx_somatic_spikes]\n",
    "        initial_time = somatic_spikes_times[0]\n",
    "        somatic_spikes_times -= initial_time\n",
    "        xmax = somatic_spikes_times[-1] + delta_time\n",
    "    \n",
    "        # postporcess dendritic AP\n",
    "        dAP_senders = dendriticAP_senders[idx_dAP]\n",
    "        dAP_currents = dendriticAP_currents[idx_dAP]\n",
    "        dAP_times = dendriticAP_times[idx_dAP]\n",
    "        dAP_times -= initial_time\n",
    "    \n",
    "        idx_exc_times = np.where((excitation_times > start_time) & (excitation_times < end_time))\n",
    "        excitation_times_sel = excitation_times[idx_exc_times]\n",
    "    \n",
    "        # ###############################\n",
    "        # draw stimulus\n",
    "        # -------------------------------\n",
    "        plt.subplot(gs[2*j, 1])\n",
    "        plt.axis('off')\n",
    "    \n",
    "        for i in range(len(sequences[seq_num])): \n",
    "    \n",
    "            x = (excitation_times_sel[i]+delta_time-initial_time) / (xmax+delta_time)\n",
    "            y = 0.26\n",
    "            arrow_width = 0.03\n",
    "            arrow_height = 0.2\n",
    "    \n",
    "            pos = [x, y]\n",
    "            X = np.array([pos, [pos[0]+arrow_width, pos[1]], [pos[0]+arrow_width/2, pos[1]-arrow_height]])\n",
    "            t1 = plt.Polygon(X, color='black')\n",
    "            plt.gca().add_patch(t1)\n",
    "            #plt.text(pos[0]+arrow_width/8, pos[1]+0.5, sequences[seq_num][i])\n",
    "            plt.text(pos[0]-0.003, pos[1]+0.1, sequences[seq_num][i])\n",
    "    \n",
    "        # ###############################\n",
    "        # show soma and dendritic spikes\n",
    "        # -------------------------------  \n",
    "        plt.subplot(gs[2*j+1, 1])\n",
    "    \n",
    "        senders_subsampled = somatic_spikes_senders[::fraction_active]\n",
    "        line1 = plt.plot(somatic_spikes_times[::fraction_active], somatic_spikes_senders[::fraction_active], 'o', color=color_soma_spike, lw=0., ms=0.5, zorder=2)\n",
    "    \n",
    "        #for k,v in count_indices_ds.items():\n",
    "        for sender in senders_subsampled:\n",
    "            idx_sub = np.where(dAP_senders == sender)\n",
    "            line2 = plt.plot(dAP_times[idx_sub], dAP_senders[idx_sub], color=color_dendrite_spike, lw=1., zorder=1)\n",
    "    \n",
    "        plt.xlim(-delta_time, xmax)\n",
    "        plt.ylim(-10, num_neurons+10)\n",
    "    \n",
    "        ticks_pos = shifted_subpopulation_indices * params['n_E']\n",
    "        ticks_label = chars_per_subpopulation\n",
    "        subpopulation_indices_background = np.arange(params['M'])*params['n_E']\n",
    "    \n",
    "        plt.yticks(ticks_pos, ticks_label)\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    \n",
    "        for i in range(params['M'])[::2]:\n",
    "            plt.axhspan(subpopulation_indices_background[i], subpopulation_indices_background[i]+params['n_E'], facecolor=fc_bg, zorder=0)\n",
    "    \n",
    "        if j == 2:\n",
    "            plt.xlabel('time (ms)')\n",
    "            plt.tick_params(labelbottom=True)\n",
    "    \n",
    "        if j == 0:\n",
    "            labels = ['somatic spikes', 'dendritic AP']\n",
    "            plt.legend((line1[0], line2[0]), labels)\n",
    "    \n",
    "    plt.savefig('/tmp/%s.png' % (master_file_name))\n",
    "\n",
    "plot_data(data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 4: Autonomous prediction\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = create_active_dendrite_parameters()\n",
    "DELAY = 0.1\n",
    "params['record_idend_last_episode'] = True\n",
    "params['syn_dict_ei']['delay'] = 2*DELAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(PS):\n",
    "    r\"\"\"from experiments/stimulus_timing_analysis/prediction_performance_analysis.py\"\"\"\n",
    "    PS_sel = copy.deepcopy(PS)\n",
    "    compute_overlap = True\n",
    "    data_path = model_instance.data_path\n",
    "    PL = shtm.helper.parameter_set_list(PS_sel)\n",
    "    \n",
    "    # get training data\n",
    "    sequences = shtm.helper.load_data(\".\", 'training_data')\n",
    "    \n",
    "    print(\"#### sequences used for training ### \")\n",
    "    for i, sequence in enumerate(sequences): \n",
    "        seq = '' \n",
    "        for char in sequence:\n",
    "            seq += str(char).ljust(2) \n",
    "        print(\"sequence %d: %s\" % (i, seq))\n",
    "    \n",
    "    fname = 'prediction_performance'\n",
    "    for cP, params in enumerate(PL):\n",
    "    \n",
    "        data = {}\n",
    "    \n",
    "        # get data path\n",
    "        print(\"\\t\\t data set %d/%d: %s/%s, Deltat %0.2f\" % (cP + 1, len(PL), data_path, fname, params['DeltaT']))\n",
    "    \n",
    "        # load somatic spikes and dendritic current\n",
    "        somatic_spikes = shtm.helper.load_spike_data(data_path, 'somatic_spikes')\n",
    "        idend_eval = shtm.helper.load_spike_data(data_path, 'idend_eval')\n",
    "    \n",
    "        # load record and excitation times \n",
    "        idend_recording_times = shtm.helper.load_data(data_path, 'idend_recording_times')\n",
    "        characters_to_subpopulations = shtm.helper.load_data(data_path, 'characters_to_subpopulations')\n",
    "        excitation_times = shtm.helper.load_data(data_path, 'excitation_times')\n",
    "    \n",
    "        # compute prediction performance\n",
    "        errors, false_positives, false_negatives, num_active_neurons = shtm.helper.compute_prediction_performance(somatic_spikes, idend_eval, idend_recording_times, characters_to_subpopulations, sequences, params)\n",
    "    \n",
    "        if compute_overlap:\n",
    "            # sequences overlap\n",
    "            sequences_overlap = shtm.helper.measure_sequences_overlap(sequences, somatic_spikes[:,1], somatic_spikes[:,0], excitation_times, params['fixed_somatic_delay'], params['learning_episodes'])\n",
    "            data['overlap'] = sequences_overlap\n",
    "    \n",
    "        data['error'] = errors\n",
    "        data['false_positive'] = false_positives\n",
    "        data['false_negative'] = false_negatives\n",
    "        data['rel_active_neurons'] = num_active_neurons/params['n_E']\n",
    "        data['ep_num'] = params['episodes_to_testing'] * np.arange(int(params['learning_episodes']/params['episodes_to_testing'])+1)\n",
    "    \n",
    "        # save data\n",
    "        np.save(\"%s/%s\" % (data_path, fname), data)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = generate_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_replay_experiment(PS):\n",
    "    r\"\"\"from experiments/stimulus_timing_analysis/replay.py\"\"\"\n",
    "    data_path = \".\"\n",
    "    PS = copy.deepcopy(PS)\n",
    "    # parameters list\n",
    "    PL = shtm.helper.parameter_set_list(PS) \n",
    " \n",
    "    #TODO: use argparse with default values\n",
    "    try: \n",
    "        batch_id=int(sys.argv[1])\n",
    "        batch_array_id=int(sys.argv[2])\n",
    "        JOBMAX=int(sys.argv[3])\n",
    "        array_id=batch_id*JOBMAX+batch_array_id\n",
    "    except:\n",
    "        array_id = 0\n",
    "\n",
    "    params = PL[array_id]\n",
    "    params['learning_episodes'] = 15 \n",
    "    params['episodes_to_testing'] = 1\n",
    "    params['load_connections'] = True\n",
    "    params['evaluate_replay'] = True\n",
    "    params['evaluate_performance'] = False\n",
    "    params['store_training_data'] = False\n",
    "    \n",
    "    # record dendritic current for only DeltaT=40.\n",
    "    # record for the sequence replay plot\n",
    "    if params['DeltaT'] == 40.:\n",
    "        params['record_idend_last_episode'] = True\n",
    "\n",
    "    params['soma_params']['V_th'] *= 0.25\n",
    "    # imporant: the adjustment of theta_dAP is only important for large interstimulus intervals (above 75ms)\n",
    "    # As the potentiation is small for large (\\DeltaT), during the predictive mode the total PSC is barely above the dAP.\n",
    "    # During the replay mode, the dispersion in the firing times causes the postsynaptic neurons to not have sufficient PSC to generate dAPs.\n",
    "    # Adjusting theta_dAP addresses this issue\n",
    "    # there might be other solutions such as increasing the number of learning episodes or adjusting the learning rates\n",
    "    params['soma_params']['theta_dAP'] *= 0.7\n",
    "    params['idend_recording_interval'] = params['dt']\n",
    "\n",
    "    # start time \n",
    "    time_start = time.time()\n",
    "\n",
    "    # ###############################################################\n",
    "    # specify sequences\n",
    "    # ===============================================================\n",
    "    sequences, _, vocabulary = shtm.helper.generate_sequences(params['task'], data_path, params['label'])\n",
    "\n",
    "    # ###############################################################\n",
    "    # create network\n",
    "    # ===============================================================\n",
    "    model_instance = Model(params, sequences, vocabulary)\n",
    "    time_model = time.time()\n",
    "\n",
    "    model_instance.create()\n",
    "    time_create = time.time()\n",
    "\n",
    "    # ###############################################################\n",
    "    # connect the netwok\n",
    "    # ===============================================================\n",
    "    model_instance.connect()\n",
    "    time_connect = time.time()\n",
    "\n",
    "    # ###############################################################\n",
    "    # train the network\n",
    "    # ===============================================================\n",
    "    # simulate network      \n",
    "    model_instance.simulate()\n",
    "    time_simulate = time.time()\n",
    "\n",
    "    print(\n",
    "        '\\nTimes of Rank {}:\\n'.format(\n",
    "            nest.Rank()) +\n",
    "        '  Total time:          {:.3f} s\\n'.format(\n",
    "            time_simulate -\n",
    "            time_start) +\n",
    "        '  Time to initialize:  {:.3f} s\\n'.format(\n",
    "            time_model -\n",
    "            time_start) +\n",
    "        '  Time to create:      {:.3f} s\\n'.format(\n",
    "            time_create -\n",
    "            time_model) +\n",
    "        '  Time to connect:     {:.3f} s\\n'.format(\n",
    "            time_connect -\n",
    "            time_create) +\n",
    "        '  Time to simulate:    {:.3f} s\\n'.format(\n",
    "            time_simulate -\n",
    "            time_connect))\n",
    "\n",
    "run_replay_experiment(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay_analysis(PS):\n",
    "    ##################################################################\n",
    "    # function to return key for any value \n",
    "    def get_key(my_dict, val): \n",
    "        for key, value in my_dict.items(): \n",
    "            if val == value: \n",
    "                return key \n",
    "    \n",
    "        return \"key doesn't exist\"\n",
    "\n",
    "    PS = copy.deepcopy(PS)\n",
    "    \n",
    "    # parameters list\n",
    "    PL = shtm.helper.parameter_set_list(PS) \n",
    "    \n",
    "    #TODO: use argparse with default values\n",
    "    try: \n",
    "        batch_id=int(sys.argv[1])\n",
    "        batch_array_id=int(sys.argv[2])\n",
    "        JOBMAX=int(sys.argv[3])\n",
    "        array_id=batch_id*JOBMAX+batch_array_id\n",
    "    except:\n",
    "        array_id = 0\n",
    "    \n",
    "    params = PL[array_id]\n",
    "    \n",
    "    # get parameters \n",
    "    #PS, PS_path = shtm.helper.get_parameter_set(path_dict)\n",
    "    num_neurons = params['M'] * params['n_E']\n",
    "    num_trials = 10\n",
    "    \n",
    "    # get trained sequences\n",
    "    sequences = shtm.helper.load_data(\".\", 'training_data')\n",
    "    len_seqs = len(sequences)\n",
    "    print(\"len_seqs = \" + str(len_seqs))\n",
    "    \n",
    "    # get data path\n",
    "    data_path = model_instance.data_path\n",
    "    \n",
    "    # load spiking data\n",
    "    somatic_spikes = shtm.helper.load_spike_data(data_path, 'somatic_spikes')\n",
    "    \n",
    "    # get excitation times \n",
    "    characters_to_subpopulations = shtm.helper.load_data(data_path, 'characters_to_subpopulations')\n",
    "    excitation_times = shtm.helper.load_data(data_path, 'excitation_times')\n",
    "    \n",
    "    #################################\n",
    "    # Postprocess data\n",
    "    # -------------------------------\n",
    "    \n",
    "    sequences_active_neurons = [[] for _ in range(len_seqs)]\n",
    "    sequences_firing_times = [[] for _ in range(len_seqs)]\n",
    "    replay_durations = []\n",
    "    #for num_trials in range(params['learning_episodes']-2):\n",
    "    for id_trial in range(num_trials-1): \n",
    "    \n",
    "        firing_times = defaultdict(list)\n",
    "        active_neurons = defaultdict(list)\n",
    "    \n",
    "        for k, seq in enumerate(sequences):\n",
    "    \n",
    "            # select data for first sequence\n",
    "            start_time = excitation_times[id_trial*len_seqs+k] \n",
    "            end_time = excitation_times[id_trial*len_seqs+1+k]\n",
    "    \n",
    "            # select somatic spikes to process\n",
    "            ind_somatic = np.where((somatic_spikes[:,1] > start_time) & (somatic_spikes[:,1] < end_time))\n",
    "    \n",
    "            times_somatic_spikes = somatic_spikes[:,1][ind_somatic]\n",
    "            senders_somatic_spikes = somatic_spikes[:,0][ind_somatic]\n",
    "            initial_time = times_somatic_spikes[0]\n",
    "            times_somatic_spikes -= initial_time\n",
    "            #xmax = times_somatic_spikes[-1] + pad_time\n",
    "    \n",
    "            for index_sender in senders_somatic_spikes:\n",
    "    \n",
    "                num_subpopulation = int((index_sender-1) / params['n_E'])\n",
    "    \n",
    "                index_time = np.where(senders_somatic_spikes == index_sender)\n",
    "                firing_times[get_key(characters_to_subpopulations, num_subpopulation)].append(times_somatic_spikes[index_time][0])\n",
    "                active_neurons[get_key(characters_to_subpopulations, num_subpopulation)].append(index_sender)\n",
    "    \n",
    "        first_letter_mean_firing_times = np.mean(firing_times[sequences[0][0]])\n",
    "        last_letter_mean_firing_times = np.mean(firing_times[sequences[0][-1]])\n",
    "    \n",
    "        replay_duration = last_letter_mean_firing_times - first_letter_mean_firing_times\n",
    "        replay_durations.append(replay_duration)\n",
    "    \n",
    "    data = {}\n",
    "    data['mean_replay_duration'] = np.mean(replay_durations)\n",
    "    data['std_replay_duration'] = np.std(replay_durations)\n",
    "    print('mean replay duration:', data['mean_replay_duration'])\n",
    "    print('std replay duration:', data['std_replay_duration'])\n",
    "    \n",
    "    print('--------------------------------------------------')\n",
    "    data_path = model_instance.data_path\n",
    "    fname = 'replay_duration' \n",
    "    print('save data to %s/%s' % (data_path, fname))\n",
    "    np.save('%s/%s' % (data_path, fname), data)\n",
    "\n",
    "replay_analysis(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence_replay(PS):\n",
    "        \n",
    "    # get data of the first seed (1st network realization)\n",
    "    PS_sel = copy.deepcopy(PS)\n",
    "    PS_sel['DeltaT'] = 40.\n",
    "    delta_idend = 1.\n",
    "    \n",
    "    params = shtm.helper.parameter_set_list(PS_sel)[0]\n",
    "    num_neurons = params['M'] * params['n_E']\n",
    "    \n",
    "    # get training data\n",
    "    sequences = load_data(\".\", 'training_data')\n",
    "    vocabulary = load_data(\".\", 'vocabulary')\n",
    "    \n",
    "    print('#### sequences used for training ### ')\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        seq = ''\n",
    "        for char in sequence:\n",
    "            seq += str(char).ljust(2)\n",
    "        print('sequence %d: %s' % (i, seq))\n",
    "    \n",
    "    # get data path\n",
    "    data_path = model_instance.data_path\n",
    "    \n",
    "    # load spikes\n",
    "    somatic_spikes = shtm.helper.load_spike_data(data_path, 'somatic_spikes')\n",
    "    idend = shtm.helper.load_spike_data(data_path, 'idend_last_episode')\n",
    "    \n",
    "    # get recoding and excitation times\n",
    "    idend_recording_times = load_data(data_path, 'idend_recording_times')\n",
    "    characters_to_subpopulations = load_data(data_path, 'characters_to_subpopulations')\n",
    "    \n",
    "    # get dendritic AP\n",
    "    idx = np.where((idend[:, 2] > params['soma_params']['I_p']-delta_idend))[0]\n",
    "    dendriticAP_currents = idend[:, 2][idx]\n",
    "    dendriticAP_times = idend[:, 1][idx]\n",
    "    dendriticAP_senders = idend[:, 0][idx]\n",
    "    \n",
    "    # get excitation times\n",
    "    excitation_times = load_data(data_path, 'excitation_times')\n",
    "    \n",
    "    #################################\n",
    "    # Plot routing \n",
    "    # -------------------------------\n",
    "    \n",
    "    # plot settings \n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['legend.fontsize'] = 6\n",
    "    plt.rcParams['figure.figsize'] = (7.,2.)\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "    panel_label_pos = (-0.12,1.1)\n",
    "    color_soma_spike = '#DB2763'\n",
    "    color_dendrite_spike = '#00B4BE' \n",
    "    fc = '#dcdcdc'\n",
    "    fraction_active = 3\n",
    "    ms = 1.\n",
    "    lw = 1.\n",
    "    \n",
    "    colormap = plt.cm.hsv\n",
    "    step = 10\n",
    "    num_plots = 10\n",
    "    tt_steps = num_plots * step\n",
    "    \n",
    "    ymin = -0.1\n",
    "    ymax = 5\n",
    "    xmin = 0\n",
    "    xmax = 40.\n",
    "    shift_x = 1.\n",
    "    shift_y = 15.\n",
    "    \n",
    "    ###################################\n",
    "    # Visualize data \n",
    "    #----------------------------------\n",
    "    \n",
    "    # organize the characters for plotting purpose\n",
    "    subpopulation_indices = []\n",
    "    chars_per_subpopulation = [] \n",
    "    for char in vocabulary:\n",
    "        # shift the subpopulation indices for plotting purposes \n",
    "        char_to_subpopulation_indices = characters_to_subpopulations[char]\n",
    "        subpopulation_indices.extend(char_to_subpopulation_indices)\n",
    "    \n",
    "        #sub_subpopulations.extend(h['characters_to_subpopulations'][char])\n",
    "        chars_per_subpopulation.extend(char * len(characters_to_subpopulations[char]))\n",
    "    \n",
    "    shifted_subpopulation_indices = np.array(subpopulation_indices) + 0.5\n",
    "    \n",
    "    ################################\n",
    "    # show soma and dendritic spikes\n",
    "    # ------------------------------ \n",
    "    fig = plt.figure()\n",
    "    gs = mpl.gridspec.GridSpec(2, 5, height_ratios=[3,15], width_ratios=[15,3,15,4,15], bottom=0.2, top=1., left=0.05, right=0.98, wspace=0., hspace=0.)\n",
    "    \n",
    "    # select data for first sequence\n",
    "    # ------------------------------\n",
    "    start_time = 0 \n",
    "    end_time = excitation_times[0] + params['DeltaT_cue']\n",
    "    \n",
    "    # select data to show for somatic spikes\n",
    "    idx_somatic_spikes = np.where((somatic_spikes[:,1] > start_time) & (somatic_spikes[:,1] < end_time))\n",
    "    \n",
    "    somatic_spikes_times = somatic_spikes[:,1][idx_somatic_spikes]\n",
    "    somatic_spikes_senders = somatic_spikes[:,0][idx_somatic_spikes]\n",
    "    initial_time = somatic_spikes_times[0]\n",
    "    somatic_spikes_times -= initial_time\n",
    "    #xmax = times_somatic_spikes[-1] + shift_x\n",
    "    \n",
    "    # select data to show for dendritic spikes\n",
    "    idx_dAP = np.where((dendriticAP_times > start_time) & (dendriticAP_times < end_time))\n",
    "    dAP_senders = dendriticAP_senders[idx_dAP]\n",
    "    dAP_currents = dendriticAP_currents[idx_dAP]\n",
    "    dAP_times = dendriticAP_times[idx_dAP]\n",
    "    dAP_times -= initial_time\n",
    "    \n",
    "    # select excitation times\n",
    "    ind_times = np.where((excitation_times > start_time) & (excitation_times < end_time))  \n",
    "    excitation_times_sel = excitation_times[ind_times]\n",
    "    \n",
    "    # draw stimulus\n",
    "    # -------------\n",
    "    plt.subplot(gs[0,0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    width = 0.03\n",
    "    height = 0.22\n",
    "    e = 0.05   # for some reason the x coordinate of the bottom point needs to be shifted to not overlap with the x-axis  \n",
    "    \n",
    "    len_x_axis = xmax + shift_x\n",
    "    \n",
    "    x = (excitation_times[0]-initial_time+shift_x+2.) / len_x_axis\n",
    "    y = height\n",
    "    pos = [x,y]\n",
    "    \n",
    "    X = np.array([pos, [pos[0]+width,pos[1]], [pos[0]+width/2, e]])\n",
    "    t1 = plt.Polygon(X, color='black')\n",
    "    plt.gca().add_patch(t1)\n",
    "    plt.text(pos[0]-0.005, pos[1]+0.1, 'A')\n",
    "    \n",
    "    # show first sequence\n",
    "    # --------------\n",
    "    ax=plt.subplot(gs[1,0])\n",
    "    #utils.panel_label('A',panel_label_pos)\n",
    "    \n",
    "    # subsamples neurons to show\n",
    "    senders_subsampled = somatic_spikes_senders[::fraction_active]\n",
    "    line1 = plt.plot(somatic_spikes_times[::fraction_active], somatic_spikes_senders[::fraction_active], 'o', color=color_soma_spike, lw=0., ms=ms, zorder=2)\n",
    "    \n",
    "    for sender in senders_subsampled:\n",
    "        ind_ds = np.where(dAP_senders == sender)\n",
    "        line2 = plt.plot(dAP_times[ind_ds], dAP_senders[ind_ds], color=color_dendrite_spike, lw=lw, zorder=1)\n",
    "    \n",
    "    #plt.xlim(-shift_x, xmax)\n",
    "    plt.ylim(-shift_y, num_neurons+shift_y)\n",
    "    plt.xlabel('time (ms)')\n",
    "    \n",
    "    conn_matrix_ticks_pos = shifted_subpopulation_indices * params['n_E']\n",
    "    conn_matrix_ticks_label = chars_per_subpopulation\n",
    "    subpopulation_indices_background = np.arange(params['M'])*params['n_E']\n",
    "    \n",
    "    plt.yticks(conn_matrix_ticks_pos, conn_matrix_ticks_label)\n",
    "    \n",
    "    for i in range(params['M'])[::2]:\n",
    "        plt.axhspan(subpopulation_indices_background[i], subpopulation_indices_background[i]+params['n_E'], facecolor=fc, zorder=0)\n",
    "    \n",
    "    #labels = ['somatic spikes', 'dendritic AP']\n",
    "    #plt.legend((line1[0], line2[0]), labels, loc='lower right')\n",
    "    \n",
    "    # select data for second sequence\n",
    "    # ------------------------------\n",
    "    start_time = excitation_times[1] \n",
    "    end_time = excitation_times[1] + params['DeltaT_cue']\n",
    "    \n",
    "    # select data to show for somatic spikes\n",
    "    idx_somatic_spikes = np.where((somatic_spikes[:,1] > start_time) & (somatic_spikes[:,1] < end_time))\n",
    "    \n",
    "    somatic_spikes_times = somatic_spikes[:,1][idx_somatic_spikes]\n",
    "    somatic_spikes_senders = somatic_spikes[:,0][idx_somatic_spikes]\n",
    "    initial_time = somatic_spikes_times[0]\n",
    "    somatic_spikes_times -= initial_time\n",
    "    #xmax = times_somatic_spikes[-1] + shift_x\n",
    "    \n",
    "    # select data to show for dendritic spikes\n",
    "    idx_dAP = np.where((dendriticAP_times > start_time) & (dendriticAP_times < end_time))\n",
    "    dAP_senders = dendriticAP_senders[idx_dAP]\n",
    "    dAP_current = dendriticAP_currents[idx_dAP]\n",
    "    dAP_times = dendriticAP_times[idx_dAP]\n",
    "    dAP_times -= initial_time\n",
    "    \n",
    "    # select excitation times\n",
    "    ind_times = np.where((excitation_times > start_time) & (excitation_times < end_time))  \n",
    "    excitation_times_sel = excitation_times[ind_times]\n",
    "    \n",
    "    # draw stimulus\n",
    "    # -------------\n",
    "    plt.subplot(gs[:,1])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(gs[0,2])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    width = 0.03\n",
    "    height = 0.25\n",
    "    e = 0.05   # for some reason the x coordinate of the bottom point needs to be shifted to not overlap with the x-axis  \n",
    "    \n",
    "    len_x_axis = xmax + shift_x\n",
    "    x = (excitation_times[1]-initial_time+shift_x+2.) / len_x_axis\n",
    "    y = height\n",
    "    pos = [x,y]\n",
    "     \n",
    "    X = np.array([pos, [pos[0]+width,pos[1]], [pos[0]+width/2, e]])\n",
    "    t1 = plt.Polygon(X, color='black')\n",
    "    plt.gca().add_patch(t1)\n",
    "    plt.text(pos[0]-0.003, pos[1]+0.1, 'F')\n",
    "    \n",
    "    # show second sequence\n",
    "    # ---------------\n",
    "    plt.subplot(gs[1,2])\n",
    "    #utils.panel_label('B',panel_label_pos)\n",
    "    \n",
    "    # subsamples neurons to show\n",
    "    senders_subsampled = somatic_spikes_senders[::fraction_active]\n",
    "    line1 = plt.plot(somatic_spikes_times[::fraction_active], somatic_spikes_senders[::fraction_active], 'o', color=color_soma_spike, lw=0., ms=ms, zorder=2)\n",
    "    \n",
    "    for sender in senders_subsampled:\n",
    "        ind_ds = np.where(dAP_senders == sender)\n",
    "        line2 = plt.plot(dAP_times[ind_ds], dAP_senders[ind_ds], color=color_dendrite_spike, lw=lw, zorder=1)\n",
    "    \n",
    "    #plt.xlim(-shift_x, xmax)\n",
    "    plt.ylim(-shift_y, num_neurons+shift_y)\n",
    "    plt.xlabel('time (ms)')\n",
    "    \n",
    "    #TODO revise this, scale should be divided by fraction_active\n",
    "    conn_matrix_ticks_pos = shifted_subpopulation_indices * params['n_E']\n",
    "    conn_matrix_ticks_label = chars_per_subpopulation\n",
    "    subpopulation_indices_background = np.arange(params['M'])* params['n_E']\n",
    "    \n",
    "    plt.yticks(conn_matrix_ticks_pos, conn_matrix_ticks_label)\n",
    "    \n",
    "    for i in range(params['M'])[::2]:\n",
    "        plt.axhspan(subpopulation_indices_background[i], subpopulation_indices_background[i]+params['n_E'], facecolor=fc, zorder=0)\n",
    "    \n",
    "    labels = ['somatic spikes', 'dendritic AP']\n",
    "    plt.legend((line1[0], line2[0]), labels, loc='upper right')\n",
    "    \n",
    "    # sequence recall duration\n",
    "    #-------------------------\n",
    "    \"\"\"\n",
    "    # gather data\n",
    "    parameter_key_list = ['seed', 'DeltaT']\n",
    "    data_key_list = ['mean_replay_duration', 'std_replay_duration']\n",
    "    lw_sd = 2. \n",
    "    bar_color = '#e8e8e8'\n",
    "    \n",
    "    fname = 'replay_duration'\n",
    "    data, params = utils.gather_data(parameter_key_list, data_key_list, path_dict, add_to_path='replay', fname=fname)\n",
    "    \n",
    "    plt.subplot(gs[1,4])\n",
    "    panel_label_pos_C = (panel_label_pos[0]-0.07, panel_label_pos[1])\n",
    "    utils.panel_label('C',panel_label_pos_C)\n",
    "    \n",
    "    mean_recall_duration = np.mean(data['mean_replay_duration'], 0)[:, 0]\n",
    "    std_recall_duration = np.std(data['mean_replay_duration'], 0)[:, 0]\n",
    "    excitation_steps = PS['DeltaT']._values\n",
    "    \n",
    "    plt.plot(excitation_steps, mean_recall_duration, lw=lw_sd, color='black')\n",
    "    plt.fill_between(excitation_steps, mean_recall_duration+std_recall_duration, mean_recall_duration-std_recall_duration, facecolor=bar_color)\n",
    "    \n",
    "    # filling in the region in which the precition performance is not optimal\n",
    "    xmin = 3\n",
    "    xmax = 85  \n",
    "    ymin = 0. #min(mean_recall_duration) - 2\n",
    "    ymax = max(mean_recall_duration) + 12\n",
    "    plt.fill_between([xmin,10], [ymin,ymin], [ymax,ymax], facecolor=fc)\n",
    "    plt.fill_between([70,xmax], [ymin,ymin], [ymax,ymax], facecolor=fc)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlabel(\"interstimulus interval $\\Delta T$ (ms)\")\n",
    "    plt.ylabel(\"replay duration (ms)\")\n",
    "    \"\"\"    \n",
    "\n",
    "    # save figure\n",
    "    path = '.'\n",
    "    fname = 'sequence_replay'\n",
    "    print('---------------------------------------------')\n",
    "    print('save figure to %s/%s.png ...' % (path, fname))\n",
    "    plt.savefig('%s/%s.png' % (path, fname))\n",
    "\n",
    "plot_sequence_replay(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(y, use_percentile=True):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation or median and percentile (5%, 95%) of the variable y\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y                : ndarray\n",
    "    use_percentile   : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean_y       : ndarray\n",
    "    mean_y_lower : ndarray\n",
    "    mean_y_upper : ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    if use_percentile:\n",
    "        mean_y = np.median(y, axis=0)\n",
    "        mean_y_lower = np.percentile(y, 5, axis=0)\n",
    "        mean_y_upper = np.percentile(y, 95, axis=0)\n",
    "    else:\n",
    "        mean_y = np.mean(y, axis=0)\n",
    "        std_y = np.std(y, axis=0)\n",
    "        mean_y_lower = mean_y - std_y\n",
    "        mean_y_upper = mean_y + std_y\n",
    "\n",
    "    return mean_y, mean_y_lower, mean_y_upper\n",
    "\n",
    "\n",
    "def plot_stimulus_timing_analysis(x, data, s, saving_paths, figure_name):\n",
    "    \"\"\" Plot prediction performance versus interstimulus intervals. The prediction performance includes error,\n",
    "    false negative and false positive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x     : array\n",
    "        contains x-axis values\n",
    "    data  : dict\n",
    "    s     : sparsity level\n",
    "        float\n",
    "        dictionary containing errors, false negatives, and false positives\n",
    "    saving_paths : list of string\n",
    "        list containing paths to where to store the figure\n",
    "    figure_name  : string\n",
    "    \"\"\"\n",
    "\n",
    "    color_shtm = 'black'\n",
    "    std_color = '#e8e8e8'\n",
    "    color_lrs = 'brown'\n",
    "    std_color_lrs = '#eeb9b9ff' #'#964b004d'\n",
    "    color_sparsity = 'grey'\n",
    "    lw = 1.5\n",
    "    lw_s = 1.5\n",
    "    lw_fn = 2.5\n",
    "    N = 1\n",
    "\n",
    "    # plot prediction error    \n",
    "    # -----------------------\n",
    "    plt.figure(figsize=(5.2, 3), constrained_layout=True)\n",
    "\n",
    "    y = mean_confidence_interval(data['error'])\n",
    "    mean_y, mean_y_lower, mean_y_upper = y\n",
    "\n",
    "    plt.plot(x, mean_y, lw=lw, color=color_shtm)\n",
    "    plt.fill_between(x, mean_y_lower, mean_y_upper, facecolor=std_color)\n",
    "\n",
    "    plt.ylabel(\"prediction error\")\n",
    "    plt.xlabel(\"interstimulus interval $\\Delta T$ (ms)\")\n",
    "\n",
    "    plt.xlim((min(x), max(x)))\n",
    "    plt.ylim(ymin=-0.1)\n",
    "\n",
    "    # combine prediction error and false negative/positive\n",
    "    # using subplots\n",
    "    # -----------------------------------------------------\n",
    "    plt.figure()\n",
    "    gs = mpl.gridspec.GridSpec(1, 4, width_ratios=[15,0.01,15,15], left=0.08, right=0.98, bottom=0.2, top=0.93, wspace=0.5, hspace=0.01)\n",
    "\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "\n",
    "    panel_label_pos = (-0.25, 1.08)\n",
    "    panel_label('A', panel_label_pos)\n",
    "\n",
    "    y = mean_confidence_interval(data['error'])\n",
    "    mean_y, mean_y_lower, mean_y_upper = y\n",
    "\n",
    "    yts = mean_confidence_interval(data['time_to_solution'])\n",
    "    mean_yts, mean_yts_lower, mean_yts_upper = yts\n",
    "\n",
    "    plt.plot(x, mean_y, lw=lw, color=color_shtm)\n",
    "    plt.fill_between(x, mean_y_lower, mean_y_upper, facecolor=std_color)\n",
    "\n",
    "    plt.ylabel(\"prediction error\")\n",
    "    plt.xlabel(\"interstimulus interval $\\Delta T$ (ms)\")\n",
    "    plt.ylim(ymin=-0.01)\n",
    "    plt.yticks(np.arange(0, max(mean_y) + 0.2, 0.2))\n",
    "    plt.xticks(np.arange(15.,max(x),15.))\n",
    "\n",
    "    # plot time to solution in the second axis\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    plt.plot(x, mean_yts, lw=lw, color=color_lrs)\n",
    "    plt.fill_between(x, mean_yts_lower, mean_yts_upper, facecolor=std_color_lrs)\n",
    "\n",
    "    plt.ylabel(\"episodes-to-solution\", color=\"brown\")\n",
    "    plt.ylim(ymin=-0.01)\n",
    "\n",
    "    ax2.tick_params(axis='y', labelcolor='brown')\n",
    "    plt.xlim((min(x), max(x)))\n",
    "\n",
    "    # plot false positive and negative\n",
    "    # --------------------------------\n",
    "    plt.subplot(gs[0, 2])\n",
    "    panel_label('B', panel_label_pos)\n",
    "\n",
    "    y_fp = mean_confidence_interval(data['false_positive'])\n",
    "    mean_y_fp, mean_y_fp_lower, mean_y_fp_upper = y_fp\n",
    "\n",
    "    y_fn = mean_confidence_interval(data['false_negative'])\n",
    "    mean_y_fn, mean_y_fn_lower, mean_y_fn_upper = y_fn\n",
    "\n",
    "    plt.plot(x, mean_y_fn, lw=lw_fn, color=color_shtm, linestyle='dashed', label='false negative')\n",
    "    plt.plot(x, mean_y_fp, lw=lw, color=color_shtm, linestyle='solid', label='false positive')\n",
    "    plt.fill_between(x, mean_y_fn_lower, mean_y_fn_upper, facecolor=std_color)\n",
    "    plt.fill_between(x, mean_y_fp_lower, mean_y_fp_upper, facecolor=std_color)\n",
    "\n",
    "    plt.xlim((min(x), max(x)))\n",
    "    plt.xlabel(\"interstimulus interval $\\Delta T$ (ms)\")\n",
    "    plt.ylabel(\"rel. frequency\")\n",
    "    plt.ylim(ymin=-0.01)\n",
    "    plt.xticks(np.arange(15.,max(x),15.))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    leg = ax.legend(loc='upper center')\n",
    "\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth(lw)\n",
    "    \"\"\"\n",
    "    # plot relative number of activate neurons\n",
    "    # ----------------------------------------\n",
    "    plt.subplot(gs[0, 3])\n",
    "    panel_label('C', panel_label_pos)\n",
    "\n",
    "    y = mean_confidence_interval(data['rel_active_neurons'])\n",
    "    x, y = running_mean(x, y, N)\n",
    "    mean_y, mean_y_lower, mean_y_upper = y\n",
    "\n",
    "    mean_y[0] = mean_y[1]\n",
    "\n",
    "    p1 = plt.plot(x, mean_y, lw=lw, color=color_shtm, linestyle='solid')\n",
    "    plt.fill_between(x, mean_y_lower, mean_y_upper, facecolor=std_color)\n",
    "    \n",
    "    # add target sparsity level\n",
    "    plt.hlines(s, x[0], x[-1], color=color_sparsity, ls='dotted', lw=lw_s)\n",
    "    \n",
    "    plt.xlim((min(x), max(x)))\n",
    "    plt.xlabel(\"interstimulus interval $\\Delta T$ (ms)\")\n",
    "    plt.ylabel(\"rel. no. of active neurons\")\n",
    "    plt.ylim(ymin=-0.01)\n",
    "    plt.xticks(np.arange(15.,max(x),15.))\n",
    "    \"\"\"\n",
    "    print('------------------------------------------------------------------')\n",
    "    for saving_path in saving_paths:\n",
    "        os.system('mkdir -p %s' % (saving_path))\n",
    "        print(\"saving figure to \" + saving_path + \"/\" + figure_name + '.png')\n",
    "        plt.savefig(saving_path + \"/\" + figure_name + '.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_replay(PS):\n",
    "    PS_trials = copy.deepcopy(PS)\n",
    "    PL = shtm.helper.parameter_set_list(PS_trials)\n",
    "    \n",
    "    # get training data\n",
    "    sequences = load_data(\".\", \"training_data\")\n",
    "    \n",
    "    print(\"#### sequences used for training ###\")\n",
    "    for i, sequence in enumerate(sequences): \n",
    "        seq = '' \n",
    "        for char in sequence:\n",
    "            seq += str(char).ljust(2) \n",
    "        print(\"sequence %d: %s\" % (i, seq))\n",
    "    \n",
    "    # load data\n",
    "    # ---------\n",
    "    data_diff_run = defaultdict(list)\n",
    "    fname = \"prediction_performance\"\n",
    "    time_to_solutions = []\n",
    "    for seed in PS['seed']:\n",
    "    \n",
    "        errors = []\n",
    "        false_positives = []\n",
    "        false_negatives = []\n",
    "        rel_active_neurons = []\n",
    "        time_to_solutions = []\n",
    "        PS_trials['seed'] = seed\n",
    "        PL = shtm.helper.parameter_set_list(PS_trials)\n",
    "    \n",
    "        for cP, params in enumerate(PL):\n",
    "    \n",
    "            # get data path\n",
    "            data_path = model_instance.data_path\n",
    "            print(\"\\t\\t data set %d/%d: %s/%s\" % (cP + 1, len(PL), data_path, fname))\n",
    "    \n",
    "            # load prediction performance\n",
    "            data = load_data(data_path, fname)\n",
    "            try:\n",
    "                idx_ts = np.where(data['error'] < 0.001)[0][0]\n",
    "                time_to_solution = idx_ts * params['episodes_to_testing']\n",
    "            except:\n",
    "                time_to_solution = params['learning_episodes']\n",
    "                idx_ts = -1\n",
    "    \n",
    "            errors.append(data['error'][-1])\n",
    "            false_positives.append(data['false_positive'][-1])\n",
    "            false_negatives.append(data['false_negative'][-1])\n",
    "            rel_active_neurons.append(data['rel_active_neurons'][-1])\n",
    "            #print(seed, data['error'][-1], data['false_positive'][-1], \n",
    "            #            data['false_negative'][-1], data['rel_active_neurons'][-1])\n",
    "    \n",
    "            time_to_solutions.append(time_to_solution)\n",
    "    \n",
    "        data_diff_run['error'].append(errors)\n",
    "        data_diff_run['false_positive'].append(false_positives)\n",
    "        data_diff_run['false_negative'].append(false_negatives)\n",
    "        data_diff_run['rel_active_neurons'].append(rel_active_neurons)\n",
    "        data_diff_run['time_to_solution'].append(time_to_solutions)\n",
    "    \n",
    "    # get x scans\n",
    "    #data_diff_run['x'] = PS['DeltaT']._values\n",
    "    s = (params['pattern_size'] - 1) / params['n_E']   # sparsity level\n",
    "    \n",
    "    # plot settings \n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['legend.fontsize'] = 6\n",
    "    plt.rcParams['figure.figsize'] = (7.,2.)\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "    panel_label_pos = (-0.1,1.0)\n",
    "    \n",
    "    print(\"plot prediction performance ...\")\n",
    "    path = '.'\n",
    "    fname = 'stimulus_timing_analysis'\n",
    "    plot_stimulus_timing_analysis(data_diff_run['x'], data_diff_run, s, saving_paths=[path], figure_name=fname)\n",
    "\n",
    "plot_replay(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "\n",
    "[1] Bouhadjar Y, Wouters DJ, Diesmann M, Tetzlaff T (2022) Sequence learning, prediction, and replay in networks of spiking neurons. PLoS Comput Biol 18(6): e1010233. https://doi.org/10.1371/journal.pcbi.1010233\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
